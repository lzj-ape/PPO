"""
å› å­æŒ–æ˜å™¨æ¨¡å— - ä¸»å…¥å£ï¼ˆå‘åå…¼å®¹ç‰ˆæœ¬ï¼‰
æ­¤æ–‡ä»¶ä¿æŒä¸åŸminer.pyçš„æ¥å£å…¼å®¹æ€§ï¼Œå†…éƒ¨å§”æ‰˜ç»™é‡æ„åçš„æ¨¡å—

é‡æ„ç»“æ„ï¼š
- miner_core.py: æ ¸å¿ƒæŒ–æ˜å™¨é€»è¾‘
- expression_generator.py: è¡¨è¾¾å¼ç”Ÿæˆ
- factor_evaluator.py: å› å­è¯„ä¼°
- ppo_trainer.py: PPOè®­ç»ƒ
- visualization.py: å¯è§†åŒ–å·¥å…·
"""

import pandas as pd
import logging
from typing import Dict, List
from pathlib import Path

from config import TrainingConfig
from miner_core import FactorMinerCore

logger = logging.getLogger(__name__)


class OptimizedSynergisticFactorMiner:
    """
    å› å­æŒ–æ˜å™¨ - å‘åå…¼å®¹çš„å…¥å£ç±»

    å†…éƒ¨å§”æ‰˜ç»™é‡æ„åçš„FactorMinerCore
    ä¿æŒæ‰€æœ‰åŸæœ‰æ¥å£ä¸å˜ï¼Œç¡®ä¿ç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹
    """

    def __init__(self,
                 data: pd.DataFrame,
                 target_col: str = 'future_return',
                 config: TrainingConfig = None,
                 max_factors: int = 15,
                 max_expr_len: int = 20):
        """
        åˆå§‹åŒ–å› å­æŒ–æ˜å™¨

        Args:
            data: å®Œæ•´æ•°æ®é›†ï¼ˆåŒ…å«OHLCVå’ŒæŠ€æœ¯æŒ‡æ ‡ï¼‰
            target_col: ç›®æ ‡å˜é‡åˆ—å
            config: è®­ç»ƒé…ç½®å¯¹è±¡
            max_factors: æœ€å¤§å› å­æ•°é‡
            max_expr_len: æœ€å¤§è¡¨è¾¾å¼é•¿åº¦
        """
        # åˆ›å»ºæ ¸å¿ƒæŒ–æ˜å™¨å®ä¾‹
        self.core = FactorMinerCore(
            data=data,
            target_col=target_col,
            config=config,
            max_factors=max_factors,
            max_expr_len=max_expr_len
        )

        # æš´éœ²å¸¸ç”¨å±æ€§ä»¥ä¿æŒå…¼å®¹æ€§
        self.config = self.core.config
        self.device = self.core.device
        self.train_data = self.core.train_data
        self.val_data = self.core.val_data
        self.test_data = self.core.test_data
        self.train_target = self.core.train_target
        self.val_target = self.core.val_target
        self.test_target = self.core.test_target
        self.feature_names = self.core.feature_names
        self.operators = self.core.operators
        self.vocab = self.core.vocab
        self.token_to_id = self.core.token_to_id
        self.id_to_token = self.core.id_to_token
        self.actor_critic = self.core.actor_critic
        self.optimizer = self.core.optimizer
        self.evaluator = self.core.evaluator
        self.combination_model = self.core.combination_model
        self.ppo_buffer = self.core.ppo_buffer
        self.training_history = self.core.training_history
        self.best_val_score = self.core.best_val_score
        self.best_model_state = self.core.best_model_state

        logger.info("OptimizedSynergisticFactorMiner initialized (using refactored modules)")

    def mine_factors(self,
                    n_iterations: int = 500,
                    batch_size: int = 8,
                    train_interval: int = 20,
                    print_interval: int = 25,
                    early_stop_patience: int = 50,
                    min_delta: float = 1e-4):
        """
        ä¸»æŒ–æ˜å¾ªç¯

        Args:
            n_iterations: æ€»è¿­ä»£æ¬¡æ•°
            batch_size: æ¯æ¬¡ç”Ÿæˆçš„è¡¨è¾¾å¼æ•°é‡
            train_interval: PPOè®­ç»ƒé—´éš”ï¼ˆæ¯Nä¸ªiterationè®­ç»ƒä¸€æ¬¡ï¼‰
            print_interval: æ‰“å°è¿›åº¦é—´éš”
            early_stop_patience: æ—©åœpatienceï¼ˆéªŒè¯é›†æ— æ”¹è¿›çš„æœ€å¤§iterationæ•°ï¼‰
            min_delta: æœ€å°æ”¹è¿›é˜ˆå€¼ï¼ˆå°äºæ­¤å€¼è§†ä¸ºæ— æ”¹è¿›ï¼‰

        Returns:
            å› å­æ± åˆ—è¡¨
        """
        return self.core.mine_factors(
            n_iterations=n_iterations,
            batch_size=batch_size,
            train_interval=train_interval,
            print_interval=print_interval,
            early_stop_patience=early_stop_patience,
            min_delta=min_delta
        )

    def get_best_factors(self, top_k: int = 5) -> List[Dict]:
        """
        è·å–æœ€ä½³å› å­

        Args:
            top_k: è¿”å›å‰kä¸ªå› å­

        Returns:
            å› å­åˆ—è¡¨
        """
        factors = []

        if self.config.combiner_type == 'linear':
            # Linearæ¨¡å¼ï¼šæŒ‰æƒé‡æ’åº
            for i, alpha_info in enumerate(self.combination_model.alpha_pool):
                factor = {
                    'tokens': alpha_info['tokens'],
                    'weight': self.combination_model.current_weights[i]
                              if self.combination_model.current_weights is not None else 0,
                    'timestamp': alpha_info.get('timestamp', 0)
                }
                factors.append(factor)

            return sorted(factors, key=lambda x: abs(x['weight']), reverse=True)[:top_k]
        else:
            # LSTMæ¨¡å¼ï¼šæŒ‰æ—¶é—´æ’åºï¼ˆæœ€æ–°çš„ï¼‰
            for alpha_info in self.combination_model.alpha_pool:
                factor = {
                    'tokens': alpha_info['tokens'],
                    'timestamp': alpha_info.get('timestamp', 0)
                }
                factors.append(factor)

            return sorted(factors, key=lambda x: x['timestamp'], reverse=True)[:top_k]

    def plot_training_history(self):
        """
        ç»˜åˆ¶è®­ç»ƒå†å²æ›²çº¿

        åŒ…æ‹¬ï¼š
        - å¥–åŠ±å˜åŒ–
        - ç»„åˆå¾—åˆ†ï¼ˆè®­ç»ƒé›†/éªŒè¯é›†ï¼‰
        - Sharpeæ¯”ç‡
        - ICæŒ‡æ ‡
        - è¿­ä»£çº§æ€§èƒ½å˜åŒ–
        - å› å­æ± å¤§å°å’Œæ¥å—ç‡
        """
        self.core.plot_training_history()

    def analyze_performance_degradation(self, train_interval: int = 20):
        """
        åˆ†æè®­ç»ƒé—´éš”å†…çš„æ€§èƒ½è¡°é€€æ¨¡å¼

        Args:
            train_interval: PPOè®­ç»ƒé—´éš”
        """
        self.core.analyze_performance_degradation(train_interval)

    def train_lstm_predictor(self,
                            epochs: int = 100,
                            batch_size: int = 64,
                            sequence_length: int = 20,
                            early_stop_patience: int = 15,
                            save_model: bool = True,
                            model_path: str = 'lstm_predictor.pt'):
        """
        è®­ç»ƒLSTMé¢„æµ‹å™¨ï¼ˆåœ¨PPOæŒ–æ˜å®Œæˆåï¼‰

        Args:
            epochs: LSTMè®­ç»ƒè½®æ•°
            batch_size: æ‰¹å¤§å°
            sequence_length: LSTMåºåˆ—é•¿åº¦
            early_stop_patience: æ—©åœpatience
            save_model: æ˜¯å¦ä¿å­˜æ¨¡å‹
            model_path: æ¨¡å‹ä¿å­˜è·¯å¾„

        Returns:
            è®­ç»ƒå¥½çš„LSTMFactorPredictorå®ä¾‹
        """
        from lstm_predictor import LSTMFactorPredictor

        logger.info("=" * 70)
        logger.info("ğŸš€ Starting LSTM Predictor Training (Post-PPO)")
        logger.info("=" * 70)

        # åˆ›å»ºLSTMé¢„æµ‹å™¨
        lstm_predictor = LSTMFactorPredictor(config=self.config)

        # å‡†å¤‡å› å­çŸ©é˜µ
        logger.info("\nğŸ“Š Preparing factor matrices...")
        train_factors = lstm_predictor.prepare_factor_matrix(
            self.combination_model.alpha_pool,
            self.train_data,
            self.operators
        )
        val_factors = lstm_predictor.prepare_factor_matrix(
            self.combination_model.alpha_pool,
            self.val_data,
            self.operators
        )
        test_factors = lstm_predictor.prepare_factor_matrix(
            self.combination_model.alpha_pool,
            self.test_data,
            self.operators
        )

        # è®­ç»ƒLSTM
        train_result = lstm_predictor.train(
            train_factors=train_factors,
            train_targets=self.train_target,
            val_factors=val_factors,
            val_targets=self.val_target,
            epochs=epochs,
            batch_size=batch_size,
            sequence_length=sequence_length,
            early_stop_patience=early_stop_patience
        )

        logger.info(f"\nâœ… LSTM Training completed!")
        logger.info(f"   Best Val IC: {train_result['best_val_ic']:.4f}")

        # ä¿å­˜æ¨¡å‹
        if save_model:
            lstm_predictor.save_model(model_path)

        return lstm_predictor

    # ==================== å†…éƒ¨è¾…åŠ©æ–¹æ³•ï¼ˆæš´éœ²ä»¥ä¿æŒå…¼å®¹æ€§ï¼‰====================

    def _tokens_to_expression(self, tokens: List[str]) -> str:
        """å°†RPNæ ¼å¼çš„tokensè½¬æ¢ä¸ºå¯è¯»è¡¨è¾¾å¼"""
        return self.core.expr_generator.tokens_to_expression(tokens)

    def _calculate_target(self, data: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—ç›®æ ‡å˜é‡"""
        return self.core._calculate_target(data)

    def _compute_feature_scales(self):
        """è®¡ç®—ç‰¹å¾æ•°é‡çº§"""
        return self.core._compute_feature_scales()

    def _build_operators(self):
        """æ„å»ºæ“ä½œç¬¦"""
        return self.core._build_operators()

    def _build_vocab(self):
        """æ„å»ºè¯æ±‡è¡¨"""
        return self.core._build_vocab()

    def _init_networks(self):
        """åˆå§‹åŒ–ç½‘ç»œ"""
        return self.core._init_networks()

    def generate_expression_batch(self, batch_size: int = 8):
        """ç”Ÿæˆè¡¨è¾¾å¼batch"""
        return self.core.expr_generator.generate_expression_batch(batch_size)

    def _evaluate_expression(self, tokens: List[str]) -> Dict:
        """è¯„ä¼°è¡¨è¾¾å¼"""
        return self.core.factor_evaluator.evaluate_expression(tokens)

    def _compute_factor_values(self, expr_tokens: List[str], data: pd.DataFrame):
        """è®¡ç®—å› å­å€¼"""
        return self.core.factor_evaluator.compute_factor_values(expr_tokens, data)

    def train_ppo_step(self) -> Dict[str, float]:
        """æ‰§è¡Œä¸€æ¬¡PPOè®­ç»ƒæ­¥éª¤"""
        return self.core.ppo_trainer.train_ppo_step(
            self.core.expr_generator._get_valid_actions
        )


# ==================== æ¨¡å—è¯´æ˜ ====================
__doc__ = """
å› å­æŒ–æ˜å™¨é‡æ„è¯´æ˜
==================

é‡æ„åçš„æ¨¡å—ç»“æ„ï¼š

1. miner_core.py (FactorMinerCore)
   - æ ¸å¿ƒæŒ–æ˜é€»è¾‘
   - æ•´åˆæ‰€æœ‰ç»„ä»¶
   - ç®¡ç†è®­ç»ƒå¾ªç¯

2. expression_generator.py (ExpressionGenerator)
   - åŸºäºPPOç­–ç•¥ç”Ÿæˆå› å­è¡¨è¾¾å¼
   - å±‚æ¬¡åŒ–åŠ¨ä½œé€‰æ‹©
   - æ•°é‡çº§å…¼å®¹æ€§æ£€æŸ¥

3. factor_evaluator.py (FactorEvaluator)
   - è®¡ç®—å› å­å€¼
   - è¯„ä¼°è¡¨è¾¾å¼æœ‰æ•ˆæ€§
   - ä¸ç»„åˆæ¨¡å‹äº¤äº’

4. ppo_trainer.py (PPOTrainer)
   - PPOç®—æ³•å®ç°
   - GAEä¼˜åŠ¿å‡½æ•°è®¡ç®—
   - ç­–ç•¥å’Œä»·å€¼ç½‘ç»œæ›´æ–°

5. visualization.py (VisualizationTools)
   - è®­ç»ƒå†å²å¯è§†åŒ–
   - æ€§èƒ½åˆ†æå·¥å…·
   - ç»“æœå±•ç¤º

ä½¿ç”¨æ–¹å¼ï¼š
---------
# æ–¹å¼1ï¼šç›´æ¥ä½¿ç”¨ï¼ˆæ¨èï¼Œæ¥å£ä¸å˜ï¼‰
from miner import OptimizedSynergisticFactorMiner
miner = OptimizedSynergisticFactorMiner(data, config=config)
factors = miner.mine_factors(n_iterations=500

# æ–¹å¼2ï¼šä½¿ç”¨æ ¸å¿ƒç±»ï¼ˆæ›´çµæ´»ï¼‰
from miner_core import FactorMinerCore
core = FactorMinerCore(data, config=config)
factors = core.mine_factors(n_iterations=500)

ä¼˜åŠ¿ï¼š
-----
1. æ¨¡å—åŒ–ï¼šæ¯ä¸ªç»„ä»¶èŒè´£æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤å’Œæµ‹è¯•
2. å¯æ‰©å±•ï¼šå¯ä»¥è½»æ¾æ›¿æ¢æˆ–å¢å¼ºå•ä¸ªæ¨¡å—
3. å¯å¤ç”¨ï¼šå„æ¨¡å—å¯ä»¥ç‹¬ç«‹ä½¿ç”¨
4. å‘åå…¼å®¹ï¼šç°æœ‰ä»£ç æ— éœ€ä¿®æ”¹
5. ä»£ç æ¸…æ™°ï¼šæ¯ä¸ªæ–‡ä»¶ä¸“æ³¨äºå•ä¸€åŠŸèƒ½

å‚è€ƒï¼š
-----
- evaluator.py: å•ä¸€èŒè´£çš„è¯„ä¼°å™¨æ¨¡å—
- combiner.py: æ¸…æ™°çš„ç»„åˆæ¨¡å‹æ¥å£
"""


if __name__ == '__main__':
    # ä½¿ç”¨ç¤ºä¾‹
    print(__doc__)
