"""
æµ‹è¯• close å› å­çš„å¾—åˆ†è®¡ç®—
"""
import sys
import os
import pandas as pd
import numpy as np
import logging

# æ·»åŠ è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)
sys.path.insert(0, os.path.join(current_dir, 'factor'))
sys.path.insert(0, os.path.join(current_dir, 'config'))
sys.path.insert(0, os.path.join(current_dir, 'utils'))

from config import TrainingConfig
from signals import SignalGenerator, PerformanceEvaluator
from evaluator import ICDiversityEvaluator
from combiner import ImprovedCombinationModel

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def load_data():
    """åŠ è½½æ•°æ®"""
    # å°è¯•å¤šä¸ªå¯èƒ½çš„æ•°æ®æ–‡ä»¶è·¯å¾„
    possible_paths = [
        '/Users/duanjin/Desktop/å¼ºåŒ–å­¦ä¹ /PPO/data/btc_15min.csv',
        '/Users/duanjin/Desktop/å¼ºåŒ–å­¦ä¹ /PPO/data/btc_data.csv',
        '/Users/duanjin/Desktop/å¼ºåŒ–å­¦ä¹ /PPO/data/data.csv',
    ]

    data = None
    for path in possible_paths:
        if os.path.exists(path):
            logger.info(f"æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {path}")
            data = pd.read_csv(path)
            break

    if data is None:
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        logger.warning("æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
        return generate_synthetic_data()

    return data

def generate_synthetic_data():
    """ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®"""
    logger.info("ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
    np.random.seed(42)
    n_bars = 3000

    # ç”Ÿæˆä»·æ ¼åºåˆ—ï¼ˆæ¨¡æ‹ŸBTCï¼‰
    returns = np.random.randn(n_bars) * 0.02 + 0.0001  # åŠ å…¥æ­£å‘æ¼‚ç§»
    prices = 10000 * np.exp(np.cumsum(returns))

    # ç”ŸæˆOHLCVæ•°æ®
    data = pd.DataFrame({
        'open': prices * (1 + np.random.randn(n_bars) * 0.005),
        'high': prices * (1 + np.abs(np.random.randn(n_bars)) * 0.01),
        'low': prices * (1 - np.abs(np.random.randn(n_bars)) * 0.01),
        'close': prices,
        'volume': np.random.rand(n_bars) * 1000 + 500,
    })

    # è°ƒæ•´highå’Œlowä»¥ç¡®ä¿åˆç†æ€§
    data['high'] = data[['open', 'close', 'high']].max(axis=1)
    data['low'] = data[['open', 'close', 'low']].min(axis=1)

    logger.info(f"ç”Ÿæˆäº† {len(data)} æ¡æ¨¡æ‹Ÿæ•°æ®")
    return data

def calculate_close_factor_score():
    """è®¡ç®— close å› å­çš„å¾—åˆ†"""
    logger.info("="*80)
    logger.info("å¼€å§‹è®¡ç®— close å› å­å¾—åˆ†...")
    logger.info("="*80)

    # 1. åŠ è½½æ•°æ®
    data = load_data()
    logger.info(f"æ•°æ®å½¢çŠ¶: {data.shape}")
    logger.info(f"æ•°æ®åˆ—: {data.columns.tolist()}")

    # 2. åˆ›å»ºé…ç½®
    config = TrainingConfig()

    # 3. å‡†å¤‡è®­ç»ƒæ•°æ®
    train_size = int(len(data) * 0.6)
    train_data = data[:train_size].copy()
    val_data = data[train_size:].copy()

    logger.info(f"è®­ç»ƒé›†å¤§å°: {len(train_data)}")
    logger.info(f"éªŒè¯é›†å¤§å°: {len(val_data)}")

    # 4. è®¡ç®—ç›®æ ‡å€¼ï¼ˆæœªæ¥æ”¶ç›Šï¼‰
    train_data['target'] = train_data['close'].pct_change(config.prediction_horizon).shift(-config.prediction_horizon)
    val_data['target'] = val_data['close'].pct_change(config.prediction_horizon).shift(-config.prediction_horizon)

    # å»æ‰NaN
    train_data = train_data.dropna()
    val_data = val_data.dropna()

    train_target = train_data['target']
    val_target = val_data['target']

    logger.info(f"è®­ç»ƒé›†æœ‰æ•ˆæ•°æ®: {len(train_data)}")
    logger.info(f"éªŒè¯é›†æœ‰æ•ˆæ•°æ®: {len(val_data)}")

    # 5. å‡†å¤‡å› å­ï¼ˆæµ‹è¯•å¤šç§ close ç›¸å…³å› å­ï¼‰
    # æ–¹æ¡ˆ1: close çš„æ”¶ç›Šç‡
    train_returns = train_data['close'].pct_change(5)  # 5æœŸåŠ¨é‡
    val_returns = val_data['close'].pct_change(5)

    # æ»šåŠ¨æ ‡å‡†åŒ–
    train_mean = train_returns.rolling(100, min_periods=20).mean()
    train_std = train_returns.rolling(100, min_periods=20).std()

    train_factor = ((train_returns - train_mean) / (train_std + 1e-8)).fillna(0).clip(-3, 3)

    # éªŒè¯é›†ä½¿ç”¨ç›¸åŒçš„ç»Ÿè®¡é‡ï¼ˆæ‰©å±•çª—å£ï¼‰
    # ä¸ºäº†ç®€åŒ–ï¼Œè¿™é‡Œä½¿ç”¨éªŒè¯é›†è‡ªå·±çš„æ»šåŠ¨ç»Ÿè®¡é‡ï¼ˆå®é™…åº”è¯¥ç”¨è®­ç»ƒé›†çš„æœ€åç»Ÿè®¡é‡ï¼‰
    val_mean = val_returns.rolling(100, min_periods=20).mean()
    val_std = val_returns.rolling(100, min_periods=20).std()
    val_factor = ((val_returns - val_mean) / (val_std + 1e-8)).fillna(0).clip(-3, 3)

    logger.info(f"\nclose åŠ¨é‡å› å­ç»Ÿè®¡ (5æœŸæ”¶ç›Šç‡):")
    logger.info(f"  è®­ç»ƒé›†: mean={train_factor.mean():.4f}, std={train_factor.std():.4f}, valid={train_factor.notna().sum()}")
    logger.info(f"  éªŒè¯é›†: mean={val_factor.mean():.4f}, std={val_factor.std():.4f}, valid={val_factor.notna().sum()}")

    # æ–¹æ¡ˆ2: ä¹Ÿæµ‹è¯•ç®€å•çš„æ ‡å‡†åŒ– close
    train_close_norm = (train_data['close'] - train_data['close'].rolling(100, min_periods=20).mean()) / (train_data['close'].rolling(100, min_periods=20).std() + 1e-8)
    train_close_norm = train_close_norm.fillna(0).clip(-3, 3)

    logger.info(f"\næ ‡å‡†åŒ– close ç»Ÿè®¡:")
    logger.info(f"  è®­ç»ƒé›†: mean={train_close_norm.mean():.4f}, std={train_close_norm.std():.4f}")

    # 6. åˆ›å»ºè¯„ä¼°å™¨
    logger.info("\nåˆ›å»ºè¯„ä¼°å™¨...")
    evaluator = ICDiversityEvaluator(config)

    # åˆ›å»º Combinerï¼ˆæ¨¡æ‹Ÿç©ºæ± å­ï¼‰
    combiner = ImprovedCombinationModel(config, max_alpha_count=15)
    combiner.set_targets(train_target, val_target)
    combiner.set_evaluator(evaluator)

    # æ³¨å…¥ combiner åˆ° evaluator
    evaluator.set_combiner(combiner)

    logger.info("è¯„ä¼°å™¨åˆ›å»ºæˆåŠŸ")

    # 7. è®¡ç®—å¾—åˆ†
    logger.info("\n" + "="*80)
    logger.info("è®¡ç®— close å› å­å¾—åˆ†...")
    logger.info("="*80)

    # è®¡ç®—å¢é‡ Sharpeï¼ˆè¯•ç®—æ¨¡å¼ï¼‰
    result = combiner.evaluate_new_factor(
        alpha_info={'name': 'close'},
        train_factor=train_factor,
        val_factor=val_factor
    )

    incremental_sharpe = result.get('train_incremental_sharpe', 0.0)
    train_stats = result.get('train_stats', {})

    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š è®¡ç®—ç»“æœ")
    logger.info("="*80)
    logger.info(f"å¢é‡ Sharpe:        {incremental_sharpe:.6f}")
    logger.info(f"è®­ç»ƒé›† Sharpe:      {train_stats.get('sharpe', 0.0):.6f}")
    logger.info(f"åŸºå‡† Sharpe:        {combiner.base_train_score:.6f} (ç©ºæ± å­)")
    logger.info(f"")
    logger.info(f"å…¥æ± é˜ˆå€¼ (ç¬¬1ä¸ª):   -0.03")
    logger.info(f"æ˜¯å¦æ»¡è¶³å…¥æ± æ¡ä»¶:   {'âœ… æ˜¯' if incremental_sharpe > -0.03 else 'âŒ å¦'}")
    logger.info("="*80)

    # 7.5 è°ƒè¯•ï¼šæŸ¥çœ‹æ»šåŠ¨ Sharpe çš„è®¡ç®—è¿‡ç¨‹
    logger.info("\n" + "="*80)
    logger.info("ğŸ” è°ƒè¯•ï¼šåˆ†ææ»šåŠ¨ Sharpe è®¡ç®—è¿‡ç¨‹")
    logger.info("="*80)

    # æ‰‹åŠ¨è®¡ç®—ä¸€æ¬¡ï¼ŒæŸ¥çœ‹ä¸­é—´ç»“æœ
    performance_eval = evaluator.performance_evaluator
    net_returns, gross_returns, signals = performance_eval.calculate_net_returns(
        train_factor, train_target
    )

    if len(net_returns) > 0:
        logger.info(f"å‡€æ”¶ç›Šåºåˆ—é•¿åº¦: {len(net_returns)}")
        logger.info(f"å‡€æ”¶ç›Šç»Ÿè®¡: mean={net_returns.mean():.6f}, std={net_returns.std():.6f}")
        logger.info(f"å‡€æ”¶ç›ŠèŒƒå›´: [{net_returns.min():.4f}, {net_returns.max():.4f}]")

        # è®¡ç®—æ»šåŠ¨ Sharpe
        bars_per_day = 24 * 60 / config.bar_minutes
        window_bars = int(3 * bars_per_day)  # 3å¤©çª—å£
        window_bars = max(30, min(window_bars, len(net_returns) // 5))

        logger.info(f"æ»šåŠ¨çª—å£å¤§å°: {window_bars} bars")

        rolling_mean = net_returns.rolling(window=window_bars, min_periods=window_bars//2).mean()
        rolling_std = net_returns.rolling(window=window_bars, min_periods=window_bars//2).std()
        rolling_std = rolling_std.replace(0, np.nan)

        rolling_sharpe = (rolling_mean / (rolling_std + 1e-9)) * np.sqrt(performance_eval.bars_per_year)
        rolling_sharpe = rolling_sharpe.dropna().clip(-50, 50)

        logger.info(f"æ»šåŠ¨ Sharpe åºåˆ—é•¿åº¦: {len(rolling_sharpe)}")
        if len(rolling_sharpe) > 0:
            logger.info(f"æ»šåŠ¨ Sharpe ç»Ÿè®¡: mean={rolling_sharpe.mean():.4f}, std={rolling_sharpe.std():.4f}")
            logger.info(f"æ»šåŠ¨ Sharpe èŒƒå›´: [{rolling_sharpe.min():.4f}, {rolling_sharpe.max():.4f}]")
            logger.info(f"æ»šåŠ¨ Sharpe å‰10ä¸ªå€¼: {rolling_sharpe.head(10).values}")

            # è®¡ç®—ç¨³å®šæ€§å¾—åˆ†
            mean_s = rolling_sharpe.mean()
            std_s = rolling_sharpe.std()
            stability_score = mean_s - 1.5 * std_s
            logger.info(f"\nç¨³å®šæ€§å¾—åˆ†è®¡ç®—:")
            logger.info(f"  Mean(Rolling Sharpe) = {mean_s:.4f}")
            logger.info(f"  Std(Rolling Sharpe) = {std_s:.4f}")
            logger.info(f"  Stability = {mean_s:.4f} - 1.5 Ã— {std_s:.4f} = {stability_score:.4f}")
        else:
            logger.warning("æ»šåŠ¨ Sharpe åºåˆ—ä¸ºç©ºï¼")
    else:
        logger.warning("å‡€æ”¶ç›Šåºåˆ—ä¸ºç©ºï¼")

    logger.info("="*80)

    # 8. è®¡ç®—è¯¦ç»†æŒ‡æ ‡
    logger.info("\nè®¡ç®—è¯¦ç»†æŒ‡æ ‡...")
    metrics = performance_eval.calculate_comprehensive_metrics(
        train_factor, train_target, window_days=3
    )

    if 'error' not in metrics:
        logger.info("\n" + "="*80)
        logger.info("ğŸ“ˆ è¯¦ç»†æŒ‡æ ‡")
        logger.info("="*80)
        logger.info(f"IC:                 {metrics['ic']:.4f}")
        logger.info(f"Sharpeæ¯”ç‡:         {metrics['sharpe_ratio']:.2f}")
        logger.info(f"Sharpeç¨³å®šæ€§:       {metrics['sharpe_stability']:.2f}")
        logger.info(f"æ€»æ”¶ç›Š:             {metrics['total_return']*100:.2f}%")
        logger.info(f"å¹´åŒ–æ”¶ç›Š:           {metrics['annual_return']*100:.2f}%")
        logger.info(f"æ³¢åŠ¨ç‡(å¹´åŒ–):       {metrics['volatility']*100:.2f}%")
        logger.info(f"æœ€å¤§å›æ’¤:           {metrics['max_drawdown']*100:.2f}%")
        logger.info(f"Calmaræ¯”ç‡:         {metrics['calmar_ratio']:.2f}")
        logger.info(f"èƒœç‡:               {metrics['win_rate']*100:.1f}%")
        logger.info(f"æ¢æ‰‹ç‡:             {metrics['turnover']:.4f}")
        logger.info(f"å¹³å‡æŒä»“:           {metrics['avg_position']:.4f}")
        logger.info(f"äº¤æ˜“å‘¨æœŸæ•°:         {metrics['num_periods']}")
        logger.info("="*80)

    return {
        'incremental_sharpe': incremental_sharpe,
        'train_sharpe': train_stats.get('sharpe', 0.0),
        'qualifies': incremental_sharpe > -0.03,
        'metrics': metrics if 'error' not in metrics else None
    }

if __name__ == "__main__":
    try:
        result = calculate_close_factor_score()

        print("\n" + "="*80)
        print("ğŸ¯ æœ€ç»ˆç»“è®º")
        print("="*80)
        if result['qualifies']:
            print(f"âœ… close å› å­æ»¡è¶³å…¥æ± æ¡ä»¶ï¼")
            print(f"   å¢é‡ Sharpe = {result['incremental_sharpe']:.6f} > -0.03")
        else:
            print(f"âŒ close å› å­ä¸æ»¡è¶³å…¥æ± æ¡ä»¶")
            print(f"   å¢é‡ Sharpe = {result['incremental_sharpe']:.6f} <= -0.03")
        print("="*80)

    except Exception as e:
        logger.error(f"è®¡ç®—è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        logger.error(traceback.format_exc())
