"""
ç®€åŒ–ç‰ˆè®¡ç®—å¤±è´¥è¯Šæ–­æµ‹è¯•
ä¸“æ³¨äºæœ€æ ¸å¿ƒçš„é—®é¢˜ï¼šä¸ºä»€ä¹ˆè¡¨è¾¾å¼è®¡ç®—ä¼šå¤±è´¥
"""

import numpy as np
import pandas as pd
import logging
import sys
from pathlib import Path

sys.path.append(str(Path(__file__).parent))

from factor.operators import TimeSeriesOperators

logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_basic_operator_issues():
    """æµ‹è¯•åŸºç¡€æ“ä½œç¬¦æ˜¯å¦æœ‰é—®é¢˜"""

    logger.info("="*80)
    logger.info("æµ‹è¯•1: åŸºç¡€æ“ä½œç¬¦è®¡ç®—")
    logger.info("="*80)

    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    np.random.seed(42)
    n = 300
    test_data = pd.DataFrame({
        'close': np.random.randn(n).cumsum() + 100,
        'volume': np.random.randint(1000, 10000, n),
    })

    ts_ops = TimeSeriesOperators()

    # æµ‹è¯•å„ç§æ“ä½œç¬¦
    operators_to_test = [
        ('sma5', lambda: ts_ops.sma(test_data['close'], 5)),
        ('sma10', lambda: ts_ops.sma(test_data['close'], 10)),
        ('sma20', lambda: ts_ops.sma(test_data['close'], 20)),
        ('std10', lambda: ts_ops.std(test_data['close'], 10)),
        ('std20', lambda: ts_ops.std(test_data['close'], 20)),
        ('delta1', lambda: ts_ops.delta(test_data['close'], 1)),
        ('rank', lambda: ts_ops.rank(test_data['close'])),
        ('zscore20', lambda: ts_ops.zscore(test_data['close'], 20)),
        ('rsi14', lambda: ts_ops.rsi(test_data['close'], 14)),
        ('abs', lambda: ts_ops.abs_op(test_data['close'])),
        ('add', lambda: ts_ops.add(test_data['close'], test_data['volume'])),
        ('div', lambda: ts_ops.div(test_data['close'], test_data['volume'])),
    ]

    success_count = 0
    fail_count = 0

    for op_name, op_func in operators_to_test:
        try:
            result = op_func()

            # æ£€æŸ¥ç»“æœè´¨é‡
            total_len = len(result)
            nan_count = result.isna().sum()
            inf_count = np.isinf(result).sum()
            valid_count = total_len - nan_count - inf_count

            valid_ratio = valid_count / total_len

            if valid_ratio >= 0.5:
                logger.info(f"âœ… {op_name:15s}: valid={valid_ratio*100:5.1f}%, "
                          f"mean={result.mean():8.4f}, std={result.std():8.4f}")
                success_count += 1
            else:
                logger.warning(f"âš ï¸  {op_name:15s}: valid={valid_ratio*100:5.1f}% (TOO LOW)")
                fail_count += 1

        except Exception as e:
            logger.error(f"âŒ {op_name:15s}: {e}")
            fail_count += 1

    logger.info(f"\nç»“æœ: æˆåŠŸ={success_count}, å¤±è´¥={fail_count}")


def test_rpn_expression_computation():
    """æµ‹è¯•RPNè¡¨è¾¾å¼çš„ç«¯åˆ°ç«¯è®¡ç®—"""

    logger.info("\n" + "="*80)
    logger.info("æµ‹è¯•2: RPNè¡¨è¾¾å¼ç«¯åˆ°ç«¯è®¡ç®—")
    logger.info("="*80)

    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    np.random.seed(42)
    n = 300
    data = pd.DataFrame({
        'open': np.random.randn(n).cumsum() + 100,
        'high': np.random.randn(n).cumsum() + 102,
        'low': np.random.randn(n).cumsum() + 98,
        'close': np.random.randn(n).cumsum() + 100,
        'volume': np.random.randint(1000, 10000, n),
    })

    ts_ops = TimeSeriesOperators()
    feature_names = ['open', 'high', 'low', 'close', 'volume']

    # æ„å»ºç®€åŒ–çš„operatorså­—å…¸
    operators = {
        'sma5': {'arity': 1, 'func': lambda x: ts_ops.sma(x, 5)},
        'sma10': {'arity': 1, 'func': lambda x: ts_ops.sma(x, 10)},
        'std20': {'arity': 1, 'func': lambda x: ts_ops.std(x, 20)},
        'delta1': {'arity': 1, 'func': lambda x: ts_ops.delta(x, 1)},
        'rank': {'arity': 1, 'func': ts_ops.rank},
        'abs': {'arity': 1, 'func': ts_ops.abs_op},
        'add': {'arity': 2, 'func': ts_ops.add},
        'sub': {'arity': 2, 'func': ts_ops.sub},
        'div': {'arity': 2, 'func': ts_ops.div},
    }

    # æµ‹è¯•è¡¨è¾¾å¼
    test_expressions = [
        (['<BEG>', 'close', 'sma5', '<SEP>'], "ç®€å•å¹³æ»‘"),
        (['<BEG>', 'close', 'sma5', 'close', 'sma10', 'sub', '<SEP>'], "åŒå‡çº¿å·®"),
        (['<BEG>', 'close', 'delta1', 'abs', '<SEP>'], "ç»å¯¹å˜åŒ–"),
        (['<BEG>', 'high', 'low', 'sub', 'close', 'div', '<SEP>'], "ä»·æ ¼èŒƒå›´æ¯”ç‡"),
        (['<BEG>', 'close', 'std20', 'rank', '<SEP>'], "æ³¢åŠ¨ç‡æ’å"),
    ]

    success_count = 0
    fail_count = 0

    for tokens, description in test_expressions:
        logger.info(f"\næµ‹è¯•: {description}")
        logger.info(f"  Tokens: {' '.join(tokens)}")

        try:
            # è®¡ç®—å› å­å€¼
            result = compute_factor_from_rpn(tokens, data, feature_names, operators)

            # æ£€æŸ¥ç»“æœ
            total_len = len(result)
            nan_count = result.isna().sum()
            inf_count = np.isinf(result).sum()
            valid_count = total_len - nan_count - inf_count
            valid_ratio = valid_count / total_len

            if valid_ratio >= 0.5:
                logger.info(f"  âœ… æˆåŠŸ: valid={valid_ratio*100:.1f}%, "
                          f"mean={result.mean():.4f}, std={result.std():.4f}")
                success_count += 1
            else:
                logger.warning(f"  âš ï¸  ä½è´¨é‡: valid={valid_ratio*100:.1f}%")
                fail_count += 1

        except Exception as e:
            logger.error(f"  âŒ å¤±è´¥: {e}")
            fail_count += 1

    logger.info(f"\nç»“æœ: æˆåŠŸ={success_count}, å¤±è´¥={fail_count}")


def compute_factor_from_rpn(tokens, data, feature_names, operators):
    """ä»RPN tokensè®¡ç®—å› å­å€¼"""
    expr_tokens = tokens[1:-1]  # å»é™¤<BEG>å’Œ<SEP>

    stack = []

    for token in expr_tokens:
        if token in feature_names:
            stack.append(data[token].copy())
        elif token in operators:
            op_info = operators[token]
            arity = op_info['arity']
            func = op_info['func']

            if len(stack) < arity:
                raise ValueError(f"Stack underflow for {token}")

            operands = [stack.pop() for _ in range(arity)]
            operands.reverse()

            result = func(*operands)
            stack.append(result)
        else:
            raise ValueError(f"Unknown token: {token}")

    if len(stack) != 1:
        raise ValueError(f"Final stack size {len(stack)} != 1")

    return stack[0]


def test_data_length_impact():
    """æµ‹è¯•æ•°æ®é•¿åº¦å¯¹è®¡ç®—æˆåŠŸç‡çš„å½±å“"""

    logger.info("\n" + "="*80)
    logger.info("æµ‹è¯•3: æ•°æ®é•¿åº¦å½±å“")
    logger.info("="*80)

    ts_ops = TimeSeriesOperators()

    # æµ‹è¯•ä¸åŒæ•°æ®é•¿åº¦
    data_lengths = [50, 100, 200, 500]

    for n in data_lengths:
        np.random.seed(42)
        data = pd.DataFrame({
            'close': np.random.randn(n).cumsum() + 100,
        })

        logger.info(f"\næ•°æ®é•¿åº¦: {n}")

        # æµ‹è¯•éœ€è¦ä¸åŒçª—å£çš„æ“ä½œç¬¦
        tests = [
            ('sma5', lambda: ts_ops.sma(data['close'], 5)),
            ('sma20', lambda: ts_ops.sma(data['close'], 20)),
            ('std10', lambda: ts_ops.std(data['close'], 10)),
            ('std20', lambda: ts_ops.std(data['close'], 20)),
        ]

        for op_name, op_func in tests:
            try:
                result = op_func()
                valid_ratio = (~result.isna()).sum() / len(result)
                logger.info(f"  {op_name:10s}: valid={valid_ratio*100:5.1f}%")
            except Exception as e:
                logger.error(f"  {op_name:10s}: {e}")


def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""

    logger.info("\n" + "="*80)
    logger.info("æµ‹è¯•4: è¾¹ç•Œæƒ…å†µ")
    logger.info("="*80)

    ts_ops = TimeSeriesOperators()

    # è¾¹ç•Œæƒ…å†µ1: åŒ…å«å¤§é‡NaNçš„æ•°æ®
    logger.info("\nè¾¹ç•Œ1: å«NaNçš„æ•°æ®")
    data_with_nan = pd.Series(np.random.randn(100))
    data_with_nan.iloc[20:40] = np.nan

    try:
        result = ts_ops.sma(data_with_nan, 10)
        valid_ratio = (~result.isna()).sum() / len(result)
        logger.info(f"  sma10 on data with NaN: valid={valid_ratio*100:.1f}%")
    except Exception as e:
        logger.error(f"  sma10 failed: {e}")

    # è¾¹ç•Œæƒ…å†µ2: å…¨0æ•°æ®
    logger.info("\nè¾¹ç•Œ2: å…¨0æ•°æ®")
    zero_data = pd.Series(np.zeros(100))

    try:
        result = ts_ops.div(pd.Series(np.ones(100)), zero_data)
        inf_count = np.isinf(result).sum()
        logger.info(f"  div by zero: {inf_count} Inf values")
    except Exception as e:
        logger.error(f"  div by zero failed: {e}")

    # è¾¹ç•Œæƒ…å†µ3: æå°æ•°æ®é›†
    logger.info("\nè¾¹ç•Œ3: æå°æ•°æ®é›†(n=10)")
    tiny_data = pd.Series(np.random.randn(10))

    for window in [5, 10, 20]:
        try:
            result = ts_ops.sma(tiny_data, window)
            valid_ratio = (~result.isna()).sum() / len(result)
            logger.info(f"  sma{window} on n=10: valid={valid_ratio*100:.1f}%")
        except Exception as e:
            logger.error(f"  sma{window} failed: {e}")


if __name__ == "__main__":
    logger.info("ğŸ” å¼€å§‹ç®€åŒ–è¯Šæ–­æµ‹è¯•\n")

    test_basic_operator_issues()
    test_rpn_expression_computation()
    test_data_length_impact()
    test_edge_cases()

    logger.info("\n" + "="*80)
    logger.info("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ")
    logger.info("="*80)
