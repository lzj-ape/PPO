"""
æ·»åŠ åˆ°ä½ çš„training notebookä¸­ä½¿ç”¨çš„è¯Šæ–­å·¥å…·

ä½¿ç”¨æ–¹æ³•:
--------
åœ¨notebookä¸­:
```python
from diagnose_utils import diagnose_failed_expressions

# åœ¨minerè®­ç»ƒå¾ªç¯ä¸­,å½“å‘ç°è®¡ç®—å¤±è´¥æ—¶:
diagnose_failed_expressions(
    failed_tokens=tokens_list,  # å¤±è´¥çš„è¡¨è¾¾å¼tokens
    miner=miner  # ä½ çš„FactorMinerCoreå®ä¾‹
)
```
"""

import logging
from typing import List, Dict
import pandas as pd
import numpy as np

logger = logging.getLogger(__name__)


def check_rpn_balance(tokens: List[str], operators: Dict, feature_names: List[str]) -> dict:
    """
    æ£€æŸ¥RPNè¡¨è¾¾å¼çš„æ ˆå¹³è¡¡

    Returns:
        dict: {
            'is_valid': bool,
            'final_stack_size': int,
            'error_message': str or None,
            'error_position': int or None
        }
    """
    if len(tokens) < 3:
        return {
            'is_valid': False,
            'final_stack_size': 0,
            'error_message': 'Expression too short',
            'error_position': 0
        }

    if tokens[0] != '<BEG>' or tokens[-1] != '<SEP>':
        return {
            'is_valid': False,
            'final_stack_size': 0,
            'error_message': 'Missing <BEG> or <SEP>',
            'error_position': 0
        }

    expr_tokens = tokens[1:-1]
    stack = 0

    for i, token in enumerate(expr_tokens):
        if token in feature_names:
            stack += 1
        elif token in operators:
            arity = operators[token]['arity']
            if stack < arity:
                return {
                    'is_valid': False,
                    'final_stack_size': stack,
                    'error_message': f'Stack underflow at token "{token}"',
                    'error_position': i + 1  # +1 for <BEG>
                }
            stack = stack - arity + 1
        else:
            return {
                'is_valid': False,
                'final_stack_size': stack,
                'error_message': f'Unknown token "{token}"',
                'error_position': i + 1
            }

    is_valid = (stack == 1)
    return {
        'is_valid': is_valid,
        'final_stack_size': stack,
        'error_message': None if is_valid else f'Final stack size is {stack}, expected 1',
        'error_position': None
    }


def try_compute_factor(tokens: List[str], data: pd.DataFrame,
                       feature_names: List[str], operators: Dict) -> dict:
    """
    å°è¯•è®¡ç®—å› å­,è¿”å›è¯¦ç»†çš„è¯Šæ–­ä¿¡æ¯

    Returns:
        dict: {
            'success': bool,
            'result': pd.Series or None,
            'valid_ratio': float,
            'nan_ratio': float,
            'inf_ratio': float,
            'error_message': str or None,
            'failed_at_token': str or None
        }
    """
    expr_tokens = tokens[1:-1]
    stack = []

    try:
        for token in expr_tokens:
            if token in feature_names:
                stack.append(data[token].copy())

            elif token in operators:
                op_info = operators[token]
                arity = op_info['arity']
                func = op_info['func']

                if len(stack) < arity:
                    return {
                        'success': False,
                        'result': None,
                        'valid_ratio': 0.0,
                        'nan_ratio': 1.0,
                        'inf_ratio': 0.0,
                        'error_message': f'Stack underflow at operator {token}',
                        'failed_at_token': token
                    }

                operands = [stack.pop() for _ in range(arity)]
                operands.reverse()

                result = func(*operands)

                if result is None:
                    return {
                        'success': False,
                        'result': None,
                        'valid_ratio': 0.0,
                        'nan_ratio': 1.0,
                        'inf_ratio': 0.0,
                        'error_message': f'Operator {token} returned None',
                        'failed_at_token': token
                    }

                stack.append(result)

        if len(stack) != 1:
            return {
                'success': False,
                'result': None,
                'valid_ratio': 0.0,
                'nan_ratio': 1.0,
                'inf_ratio': 0.0,
                'error_message': f'Final stack size {len(stack)} != 1',
                'failed_at_token': None
            }

        final_result = stack[0]
        total_len = len(final_result)
        nan_count = final_result.isna().sum()
        inf_count = np.isinf(final_result).sum()
        valid_count = total_len - nan_count - inf_count

        return {
            'success': True,
            'result': final_result,
            'valid_ratio': valid_count / total_len,
            'nan_ratio': nan_count / total_len,
            'inf_ratio': inf_count / total_len,
            'error_message': None,
            'failed_at_token': None
        }

    except Exception as e:
        return {
            'success': False,
            'result': None,
            'valid_ratio': 0.0,
            'nan_ratio': 1.0,
            'inf_ratio': 0.0,
            'error_message': str(e),
            'failed_at_token': token if 'token' in locals() else None
        }


def diagnose_failed_expressions(failed_tokens_list: List[List[str]], miner) -> None:
    """
    è¯Šæ–­å¤±è´¥çš„è¡¨è¾¾å¼åˆ—è¡¨

    Args:
        failed_tokens_list: å¤±è´¥çš„è¡¨è¾¾å¼tokensåˆ—è¡¨
        miner: FactorMinerCoreå®ä¾‹
    """
    logger.info("="*80)
    logger.info("ğŸ” å¼€å§‹è¯Šæ–­å¤±è´¥çš„è¡¨è¾¾å¼")
    logger.info("="*80)

    if not failed_tokens_list:
        logger.info("æ²¡æœ‰å¤±è´¥çš„è¡¨è¾¾å¼éœ€è¦è¯Šæ–­")
        return

    logger.info(f"å¤±è´¥è¡¨è¾¾å¼æ•°é‡: {len(failed_tokens_list)}")

    # ç»Ÿè®¡
    balance_failures = 0
    computation_failures = 0
    low_quality_results = 0

    for idx, tokens in enumerate(failed_tokens_list[:10]):  # åªè¯Šæ–­å‰10ä¸ª
        logger.info(f"\n{'='*80}")
        logger.info(f"è¡¨è¾¾å¼ {idx+1}/{len(failed_tokens_list)}")
        logger.info(f"Tokens: {' '.join(tokens)}")

        # 1. æ£€æŸ¥æ ˆå¹³è¡¡
        balance_result = check_rpn_balance(
            tokens,
            miner.operators,
            miner.feature_names
        )

        if not balance_result['is_valid']:
            logger.error(f"âŒ æ ˆå¹³è¡¡æ£€æŸ¥å¤±è´¥:")
            logger.error(f"   {balance_result['error_message']}")
            if balance_result['error_position'] is not None:
                logger.error(f"   é”™è¯¯ä½ç½®: ç¬¬{balance_result['error_position']}ä¸ªtoken")
            logger.error(f"   æœ€ç»ˆæ ˆå¤§å°: {balance_result['final_stack_size']}")
            balance_failures += 1
            continue

        logger.info(f"âœ… æ ˆå¹³è¡¡æ£€æŸ¥é€šè¿‡ (æ ˆå¤§å°=1)")

        # 2. å°è¯•è®¡ç®—
        compute_result = try_compute_factor(
            tokens,
            miner.train_data,
            miner.feature_names,
            miner.operators
        )

        if not compute_result['success']:
            logger.error(f"âŒ è®¡ç®—å¤±è´¥:")
            logger.error(f"   {compute_result['error_message']}")
            if compute_result['failed_at_token']:
                logger.error(f"   å¤±è´¥äºtoken: {compute_result['failed_at_token']}")
            computation_failures += 1
            continue

        # 3. æ£€æŸ¥ç»“æœè´¨é‡
        valid_ratio = compute_result['valid_ratio']
        nan_ratio = compute_result['nan_ratio']
        inf_ratio = compute_result['inf_ratio']

        logger.info(f"âœ… è®¡ç®—æˆåŠŸ:")
        logger.info(f"   æœ‰æ•ˆç‡: {valid_ratio*100:.1f}%")
        logger.info(f"   NaNç‡: {nan_ratio*100:.1f}%")
        logger.info(f"   Infç‡: {inf_ratio*100:.1f}%")

        if valid_ratio < 0.5:
            logger.warning(f"âš ï¸  ç»“æœè´¨é‡ä½ (æœ‰æ•ˆç‡ < 50%)")
            low_quality_results += 1

        if compute_result['result'] is not None:
            result = compute_result['result']
            logger.info(f"   å‡å€¼: {result.mean():.4f}")
            logger.info(f"   æ ‡å‡†å·®: {result.std():.4f}")

    # è¾“å‡ºæ€»ç»“
    logger.info(f"\n{'='*80}")
    logger.info("ğŸ“Š è¯Šæ–­æ€»ç»“")
    logger.info(f"{'='*80}")
    logger.info(f"æ ˆå¹³è¡¡å¤±è´¥: {balance_failures}/{len(failed_tokens_list)}")
    logger.info(f"è®¡ç®—å¤±è´¥: {computation_failures}/{len(failed_tokens_list)}")
    logger.info(f"ä½è´¨é‡ç»“æœ: {low_quality_results}/{len(failed_tokens_list)}")
    logger.info(f"{'='*80}\n")


def diagnose_single_expression(tokens: List[str], miner, verbose: bool = True) -> dict:
    """
    è¯Šæ–­å•ä¸ªè¡¨è¾¾å¼

    Returns:
        dict: åŒ…å«æ‰€æœ‰è¯Šæ–­ä¿¡æ¯
    """
    result = {
        'tokens': tokens,
        'balance_check': None,
        'computation': None
    }

    # æ£€æŸ¥æ ˆå¹³è¡¡
    result['balance_check'] = check_rpn_balance(
        tokens,
        miner.operators,
        miner.feature_names
    )

    if not result['balance_check']['is_valid']:
        if verbose:
            logger.error(f"æ ˆå¹³è¡¡å¤±è´¥: {result['balance_check']['error_message']}")
        return result

    # å°è¯•è®¡ç®—
    result['computation'] = try_compute_factor(
        tokens,
        miner.train_data,
        miner.feature_names,
        miner.operators
    )

    if verbose:
        if result['computation']['success']:
            logger.info(f"âœ… è¡¨è¾¾å¼æœ‰æ•ˆ: {' '.join(tokens)}")
            logger.info(f"   æœ‰æ•ˆç‡: {result['computation']['valid_ratio']*100:.1f}%")
        else:
            logger.error(f"âŒ è®¡ç®—å¤±è´¥: {result['computation']['error_message']}")

    return result


# ä½¿ç”¨ç¤ºä¾‹
"""
# åœ¨ä½ çš„è®­ç»ƒå¾ªç¯ä¸­:

# 1. æ”¶é›†å¤±è´¥çš„è¡¨è¾¾å¼
failed_expressions = []

# åœ¨batchå¤„ç†ä¸­,å½“å‘ç°å¤±è´¥æ—¶:
for tokens, state_ids, trajectory in batch_results:
    try:
        factor_values = miner.factor_evaluator.compute_factor_train(tokens)
        if factor_values is None:
            failed_expressions.append(tokens)
    except:
        failed_expressions.append(tokens)

# 2. æ‰¹é‡è¯Šæ–­
if len(failed_expressions) > 0:
    from diagnose_utils import diagnose_failed_expressions
    diagnose_failed_expressions(failed_expressions, miner)

# 3. æˆ–è€…è¯Šæ–­å•ä¸ªè¡¨è¾¾å¼
from diagnose_utils import diagnose_single_expression
result = diagnose_single_expression(['<BEG>', 'close', 'sma5', '<SEP>'], miner)
"""
