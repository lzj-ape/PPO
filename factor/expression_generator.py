"""
è¡¨è¾¾å¼ç”Ÿæˆå™¨æ¨¡å—
è´Ÿè´£ç”Ÿæˆå’ŒéªŒè¯å› å­è¡¨è¾¾å¼
"""

import numpy as np
import pandas as pd
import torch
import torch.nn.functional as F
from torch.distributions import Categorical
from typing import Dict, List, Tuple, Optional
import logging

try:
    from torch.amp import autocast
except ImportError:
    from torch.cuda.amp import autocast

logger = logging.getLogger(__name__)


class ExpressionGenerator:
    """è¡¨è¾¾å¼ç”Ÿæˆå™¨ - ä½¿ç”¨PPOç­–ç•¥ç½‘ç»œç”Ÿæˆå› å­è¡¨è¾¾å¼"""

    def __init__(self,
                 actor_critic,
                 vocab: List[str],
                 token_to_id: Dict[str, int],
                 id_to_token: Dict[int, str],
                 operators: Dict,
                 feature_names: List[str],
                 feature_scales: Dict[str, float],
                 max_expr_len: int = 20,
                 device: torch.device = None,
                 use_amp: bool = False):
        """
        åˆå§‹åŒ–è¡¨è¾¾å¼ç”Ÿæˆå™¨

        Args:
            actor_critic: PPOçš„Actor-Criticç½‘ç»œ
            vocab: è¯æ±‡è¡¨
            token_to_id: tokenåˆ°idçš„æ˜ å°„
            id_to_token: idåˆ°tokençš„æ˜ å°„
            operators: æ“ä½œç¬¦å­—å…¸
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            feature_scales: ç‰¹å¾æ•°é‡çº§å­—å…¸
            max_expr_len: æœ€å¤§è¡¨è¾¾å¼é•¿åº¦
            device: è®¡ç®—è®¾å¤‡
            use_amp: æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦
        """
        self.actor_critic = actor_critic
        self.vocab = vocab
        self.token_to_id = token_to_id
        self.id_to_token = id_to_token
        self.operators = operators
        self.feature_names = feature_names
        self.feature_scales = feature_scales
        self.max_expr_len = max_expr_len
        self.device = device or torch.device('cpu')
        self.use_amp = use_amp

        self.pad_token_id = token_to_id['<PAD>']

    def generate_expression_batch(self, batch_size: int = 8) -> List[Tuple[List[str], List[int], Dict]]:
        """
        æ‰¹é‡ç”Ÿæˆè¡¨è¾¾å¼

        Args:
            batch_size: æ‰¹å¤§å°

        Returns:
            List[(tokens, state_ids, trajectory)]
        """
        batch_states = [[self.token_to_id['<BEG>']] for _ in range(batch_size)]
        batch_tokens = [['<BEG>'] for _ in range(batch_size)]
        batch_finished = [False] * batch_size
        batch_trajectories = [
            {
                'states': [],
                'actions': [],
                'types': [],
                'type_log_probs': [],
                'action_log_probs': [],
                'values': []
            }
            for _ in range(batch_size)
        ]

        for step in range(self.max_expr_len - 1):
            active_indices = [i for i in range(batch_size) if not batch_finished[i]]

            if not active_indices:
                break

            active_states = [batch_states[i] for i in active_indices]
            active_valid_info = [self._get_valid_actions(state) for state in active_states]

            with torch.no_grad():
                if self.use_amp:
                    with autocast(device_type='cuda'):
                        type_logits_batch, action_logits_batch, values_batch = \
                            self.actor_critic.forward_batch(active_states)
                else:
                    type_logits_batch, action_logits_batch, values_batch = \
                        self.actor_critic.forward_batch(active_states)

            for idx, i in enumerate(active_indices):
                valid_types, valid_actions_by_type = active_valid_info[idx]

                if len(valid_types) == 1 and valid_types[0] == 2:
                    batch_tokens[i].append('<SEP>')
                    batch_finished[i] = True
                    continue

                value = values_batch[idx]

                # Step 1: é‡‡æ ·åŠ¨ä½œç±»å‹
                type_logits = type_logits_batch[idx]
                type_mask = torch.full((3,), float('-inf'), device=self.device)
                type_mask[valid_types] = 0.0
                masked_type_logits = type_logits + type_mask

                type_probs = F.softmax(masked_type_logits, dim=-1)
                type_dist = Categorical(type_probs)
                action_type_tensor = type_dist.sample()
                action_type = action_type_tensor.item()
                type_log_prob = type_dist.log_prob(action_type_tensor).item()

                # Step 2: é‡‡æ ·å…·ä½“åŠ¨ä½œ
                valid_actions_for_type = valid_actions_by_type[action_type]
                action_logits = action_logits_batch[idx]

                action_mask = torch.full((len(self.vocab),), float('-inf'), device=self.device)
                action_mask[valid_actions_for_type] = 0.0
                masked_action_logits = action_logits + action_mask

                action_probs = F.softmax(masked_action_logits, dim=-1)
                action_dist = Categorical(action_probs)
                action_tensor = action_dist.sample()
                action = action_tensor.item()
                action_log_prob = action_dist.log_prob(action_tensor).item()

                # ä¿å­˜trajectory
                batch_trajectories[i]['states'].append(batch_states[i].copy())
                batch_trajectories[i]['types'].append(action_type)
                batch_trajectories[i]['actions'].append(action)
                batch_trajectories[i]['type_log_probs'].append(type_log_prob)
                batch_trajectories[i]['action_log_probs'].append(action_log_prob)
                batch_trajectories[i]['values'].append(value.item())

                token = self.id_to_token[action]
                batch_tokens[i].append(token)
                batch_states[i].append(action)

                if token == '<SEP>':
                    batch_finished[i] = True

        # ğŸ”¥ ä¿®å¤ï¼šå¾ªç¯ç»“æŸåï¼Œä¸ºæ‰€æœ‰æœªå®Œæˆçš„è¡¨è¾¾å¼å¼ºåˆ¶æ·»åŠ  <SEP>
        # åŒæ—¶ç¡®ä¿è¡¨è¾¾å¼è‡³å°‘æœ‰1ä¸ªæœ‰æ•ˆtokenï¼ˆé™¤äº†<BEG>å’Œ<SEP>ï¼‰
        for i in range(batch_size):
            if not batch_finished[i]:
                # æ£€æŸ¥æ˜¯å¦æœ‰è‡³å°‘1ä¸ªæœ‰æ•ˆtokenï¼ˆé™¤äº†<BEG>ï¼‰
                if len(batch_tokens[i]) < 2:
                    # æç«¯æƒ…å†µï¼šåªæœ‰<BEG>ï¼Œæ·»åŠ ä¸€ä¸ªé»˜è®¤ç‰¹å¾
                    default_feature = 'close' if 'close' in self.feature_names else self.feature_names[0]
                    batch_tokens[i].append(default_feature)
                    batch_states[i].append(self.token_to_id[default_feature])
                    logger.warning(f"Expression {i} had only <BEG>, added default feature '{default_feature}'")

                # æ·»åŠ <SEP>
                batch_tokens[i].append('<SEP>')
                batch_states[i].append(self.token_to_id['<SEP>'])
                logger.debug(f"Force-added <SEP> to incomplete expression {i}")

        results = []
        for i in range(batch_size):
            results.append((batch_tokens[i], batch_states[i], batch_trajectories[i]))

        return results

    def _get_valid_actions(self, state: List[int]) -> Tuple[List[int], Dict[int, List[int]]]:
        """
        å±‚æ¬¡åŒ–åŠ¨ä½œé€‰æ‹© - ä¸¥æ ¼ä¿è¯RPNæ ˆå¹³è¡¡

        è¯­æ³•çº¦æŸå¼ºåŒ–ç­–ç•¥:
        1. æœ€å°é•¿åº¦: è‡³å°‘ <BEG> feature operator <SEP> (len>=4)
        2. å¼ºåˆ¶ç»“æŸ: stack==1 ä¸” len>=4 â†’ å¿…é¡»è¾“å‡º <SEP>
        3. ç¦æ­¢æ—©åœ: stack!=1 â†’ ç¦æ­¢è¾“å‡º <SEP>
        4. æ¸è¿›å¼çº¦æŸ: æ ¹æ®å‰©ä½™ç©ºé—´å’Œå½“å‰æ ˆå¤§å°åŠ¨æ€é™åˆ¶ç‰¹å¾æ·»åŠ 
        5. æ“ä½œç¬¦çº¦æŸ: åªæœ‰æ ˆè¶³å¤Ÿå¤§æ—¶æ‰èƒ½ä½¿ç”¨å¯¹åº”arityçš„æ“ä½œç¬¦

        Returns:
            (valid_types, valid_actions_by_type)
        """
        current_len = len(state)
        MIN_VALID_LEN = 4  # <BEG> feature op <SEP>

        stack_size = self._calculate_stack_size(state)
        scale_stack = self._get_scale_stack(state)

        # ğŸ”¥ çº¦æŸ1: å½“stack==1ä¸”è¾¾åˆ°æœ€å°é•¿åº¦æ—¶,åªèƒ½ç»“æŸ
        if stack_size == 1 and current_len >= MIN_VALID_LEN:
            return [2], {2: [self.token_to_id['<SEP>']]}

        # ğŸ”¥ çº¦æŸ2: æ¸è¿›å¼çº¦æŸ - æ ¹æ®å‰©ä½™ç©ºé—´å’Œæ ˆå¤§å°å†³å®šæ˜¯å¦å…è®¸æ·»åŠ ç‰¹å¾
        remaining_space = self.max_expr_len - current_len - 1  # -1 for <SEP>
        min_ops_needed = max(0, stack_size - 1)  # éœ€è¦æ¶ˆè€—åˆ°stack=1æ‰€éœ€çš„æœ€å°‘æ“ä½œç¬¦æ•°

        valid_types = []
        valid_actions_by_type = {}

        # ğŸ”¥ çº¦æŸ3: åªæœ‰æ ˆæœ‰æ•ˆ(stack>=0)æ—¶æ‰èƒ½æ·»åŠ feature/operator
        if stack_size >= 0:
            # Type 0: Features - åŠ¨æ€é™åˆ¶
            # åˆ¤æ–­æ˜¯å¦è¿˜æœ‰ç©ºé—´æ·»åŠ ç‰¹å¾
            # æ·»åŠ ä¸€ä¸ªç‰¹å¾åï¼Œè‡³å°‘éœ€è¦ min_ops_needed+1 ä¸ªæ“ä½œç¬¦æ‰èƒ½å¹³è¡¡æ ˆ
            space_needed_if_add_feature = (min_ops_needed + 1) + 1  # æ“ä½œç¬¦ + <SEP>

            # ğŸ”¥ å…³é”®æ”¹è¿›1: åŸºäºå‰©ä½™ç©ºé—´çš„é™åˆ¶
            can_add_feature_by_space = remaining_space > space_needed_if_add_feature

            # ğŸ”¥ å…³é”®æ”¹è¿›2: åŸºäºæ ˆå¤§å°çš„é™åˆ¶ - æ ˆå¤ªå¤§æ—¶ç¦æ­¢ç»§ç»­æ·»åŠ 
            # ä½¿ç”¨ä¸€ä¸ªå¯å‘å¼è§„åˆ™: æ ˆå¤§å°ä¸åº”è¶…è¿‡å‰©ä½™ç©ºé—´çš„ä¸€åŠ
            # è¿™æ ·ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ“ä½œç¬¦æ¥æ¶ˆè€—æ ˆ
            max_reasonable_stack = max(3, remaining_space // 2)
            can_add_feature_by_stack = stack_size < max_reasonable_stack

            # ä¸¤ä¸ªæ¡ä»¶éƒ½æ»¡è¶³æ‰å…è®¸æ·»åŠ ç‰¹å¾
            if can_add_feature_by_space and can_add_feature_by_stack:
                feature_actions = [self.token_to_id[f] for f in self.feature_names]
                if feature_actions:
                    valid_types.append(0)
                    valid_actions_by_type[0] = feature_actions
            # å¦åˆ™ç¦æ­¢æ·»åŠ ç‰¹å¾ï¼Œå¿…é¡»ä¼˜å…ˆä½¿ç”¨æ“ä½œç¬¦æ¶ˆè€—æ ˆ

            # Type 1: Operators - ä¸¥æ ¼æ£€æŸ¥æ ˆå¤§å°å’Œæ•°é‡çº§
            operator_actions = []
            for op_name, op_info in self.operators.items():
                arity = op_info['arity']

                # ğŸ”¥ æ ¸å¿ƒçº¦æŸ: æ ˆå¿…é¡»è¶³å¤Ÿå¤§æ‰èƒ½åº”ç”¨è¯¥æ“ä½œç¬¦
                if stack_size >= arity:
                    # æ£€æŸ¥æ•°é‡çº§å…¼å®¹æ€§
                    if self._is_operator_scale_compatible(op_name, scale_stack):
                        # ğŸ”¥ é¢å¤–çº¦æŸ: åº”ç”¨æ“ä½œåæ ˆå¤§å°ä¼šå˜ä¸º stack - arity + 1
                        # å¿…é¡»ç¡®ä¿åº”ç”¨åè‡³å°‘æœ‰1ä¸ªå…ƒç´ (æœ€ç»ˆèƒ½ç»“æŸ)
                        new_stack_size = stack_size - arity + 1
                        if new_stack_size >= 1:
                            operator_actions.append(self.token_to_id[op_name])

            if operator_actions:
                valid_types.append(1)
                valid_actions_by_type[1] = operator_actions

        # ğŸ”¥ çº¦æŸ4: å¦‚æœæ²¡æœ‰æœ‰æ•ˆåŠ¨ä½œ,å¼ºåˆ¶ç»“æŸ(å…œåº•,é˜²æ­¢æ­»é”)
        # è¿™ç§æƒ…å†µå¯èƒ½å‘ç”Ÿåœ¨ï¼šæ ˆå¤§å°>1ä½†ç©ºé—´ä¸è¶³ä»¥æ¶ˆè€—åˆ°1
        if not valid_types:
            # æ— æ³•ç»§ç»­ç”Ÿæˆæœ‰æ•ˆè¡¨è¾¾å¼ï¼Œåªèƒ½å¼ºåˆ¶ç»“æŸ
            logger.warning(f"No valid actions at state len={current_len}, stack={stack_size}, "
                         f"remaining_space={remaining_space}, forcing <SEP> (will be INVALID)")
            return [2], {2: [self.token_to_id['<SEP>']]}

        return valid_types, valid_actions_by_type

    def _calculate_stack_size(self, state: List[int]) -> int:
        """è®¡ç®—è¡¨è¾¾å¼æ ˆçš„å¤§å°"""
        if len(state) <= 1:
            return 0

        stack = 0
        for token_id in state[1:]:
            token = self.id_to_token[token_id]

            if token in self.feature_names:
                stack += 1
            elif token in self.operators:
                arity = self.operators[token]['arity']
                stack = stack - arity + 1
                if stack < 0:
                    return -1
            elif token == '<SEP>':
                break

        return stack

    def _get_scale_stack(self, state: List[int]) -> List[float]:
        """è·å–å½“å‰è¡¨è¾¾å¼çš„æ•°é‡çº§æ ˆ"""
        scale_stack = []

        for token_id in state[1:]:  # è·³è¿‡<BEG>
            token = self.id_to_token[token_id]

            if token in self.feature_names:
                scale = self.feature_scales.get(token, 1.0)
                scale_stack.append(scale)

            elif token in self.operators:
                op_info = self.operators[token]
                arity = op_info['arity']

                if len(scale_stack) < arity:
                    return []

                operand_scales = []
                for _ in range(arity):
                    operand_scales.append(scale_stack.pop())
                operand_scales.reverse()

                # è®¡ç®—ç»“æœæ•°é‡çº§
                result_scale = self._compute_result_scale(token, operand_scales)
                scale_stack.append(result_scale)

            elif token == '<SEP>':
                break

        return scale_stack

    def _compute_result_scale(self, op_name: str, operand_scales: List[float]) -> float:
        """è®¡ç®—æ“ä½œç»“æœçš„æ•°é‡çº§"""
        arity = len(operand_scales)

        if arity == 1:
            # å½’ä¸€åŒ–åˆ°[0,1]çš„ä¸€å…ƒç®—å­
            if op_name in ['sigmoid', 'rank', 'ts_rank10']:
                return 1.0
            # å½’ä¸€åŒ–åˆ°[-1,1]çš„ä¸€å…ƒç®—å­
            elif op_name in ['tanh', 'sign']:
                return 1.0
            # RSIç­‰å›ºå®šèŒƒå›´ç®—å­
            elif op_name in ['rsi14']:
                return 50.0
            # ä¿æŒæ•°é‡çº§çš„ç®—å­
            elif op_name in ['abs', 'delay1', 'delay3']:
                return operand_scales[0]
            # æ”¹å˜æ•°é‡çº§ä¸ºæ— é‡çº²çš„ç®—å­
            elif op_name in ['log', 'exp']:
                return 1.0
            # ç›¸å¯¹å˜åŒ–ç±»ç®—å­
            elif op_name in ['delta1', 'momentum5', 'roc10']:
                return operand_scales[0] * 0.1
            # å¹³æ»‘ç±»ç®—å­
            elif op_name in ['sma5', 'sma10', 'sma20', 'ema5', 'ema10',
                            'wma10', 'dema10', 'tema10']:
                return operand_scales[0]
            # æ³¢åŠ¨ç‡ç±»ç®—å­
            elif op_name in ['std10', 'std20', 'variance20', 'mad20']:
                return operand_scales[0]
            # åˆ†ä½æ•°
            elif op_name in ['quantile20', 'ts_min10', 'ts_max10']:
                return operand_scales[0]
            # å¹‚ã€å¹³æ–¹æ ¹
            elif op_name in ['pow', 'sqrt']:
                return operand_scales[0]
            # æ ‡å‡†åŒ–ç±»ç®—å­
            elif op_name in ['zscore20', 'scale']:
                return 1.0
            # æŠ€æœ¯æŒ‡æ ‡
            elif op_name in ['macd', 'bb_upper', 'bb_lower']:
                return operand_scales[0]
            # åŠ æƒç±»ç®—å­
            elif op_name in ['decay10']:
                return operand_scales[0]
            # è¿ä¹˜ç®—å­
            elif op_name in ['ts_prod10']:
                return 1.0
            else:
                return operand_scales[0]

        elif arity == 2:
            if op_name in ['add', 'sub', 'max', 'min']:
                return np.mean(operand_scales)
            elif op_name == 'mul':
                return operand_scales[0] * operand_scales[1]
            elif op_name == 'div':
                if operand_scales[1] > 1e-10:
                    return operand_scales[0] / operand_scales[1]
                else:
                    return operand_scales[0]
            elif op_name in ['corr20', 'covar']:
                return 1.0
            else:
                return np.mean(operand_scales)

        elif arity == 3:
            if op_name == 'condition':
                return np.mean([operand_scales[1], operand_scales[2]])
            else:
                return np.mean(operand_scales)

        else:
            return np.mean(operand_scales) if operand_scales else 1.0

    def _is_operator_scale_compatible(self, op_name: str, scale_stack: List[float]) -> bool:
        """æ£€æŸ¥æ“ä½œç¬¦æ˜¯å¦ä¸å½“å‰æ•°é‡çº§æ ˆå…¼å®¹"""
        if op_name not in self.operators:
            return False

        op_info = self.operators[op_name]
        arity = op_info['arity']
        scale_rule = op_info.get('scale_rule', 'any')
        scale_threshold = op_info.get('scale_threshold', None)

        if len(scale_stack) < arity:
            return False

        if scale_rule == 'any':
            return True

        if scale_rule == 'similar_only':
            if arity == 2:
                scale1 = scale_stack[-2]
                scale2 = scale_stack[-1]

                if scale1 == 0 or scale2 == 0:
                    return scale1 == scale2

                ratio = max(scale1, scale2) / min(scale1, scale2)
                threshold = scale_threshold if scale_threshold is not None else 100.0
                return ratio <= threshold
            return True

        return True

    def tokens_to_expression(self, tokens: List[str]) -> str:
        """å°†RPNæ ¼å¼çš„tokensè½¬æ¢ä¸ºå¯è¯»è¡¨è¾¾å¼"""
        if not tokens or tokens[0] != '<BEG>' or tokens[-1] != '<SEP>':
            return 'INVALID_EXPRESSION'

        stack: List[str] = []
        expr_tokens = tokens[1:-1]

        try:
            for token in expr_tokens:
                if token in self.feature_names:
                    stack.append(token)
                elif token in self.operators:
                    op_info = self.operators[token]
                    arity = op_info['arity']
                    if len(stack) < arity:
                        return 'INVALID_EXPRESSION'

                    args = [stack.pop() for _ in range(arity)]
                    args.reverse()
                    arg_str = ', '.join(args)
                    expr = f"{token}({arg_str})"
                    stack.append(expr)
                else:
                    return 'INVALID_EXPRESSION'

            if len(stack) != 1:
                return 'INVALID_EXPRESSION'

            return stack[0]
        except Exception as exc:
            logger.debug(f"Expression stringify error: {exc}")
            return 'INVALID_EXPRESSION'
