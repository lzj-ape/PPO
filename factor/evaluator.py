import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Optional
from config import TrainingConfig

logger = logging.getLogger(__name__)

class ICDiversityEvaluator:
    """
    åŸºäºç»„åˆå¢é‡å¤æ™®æ¯”ç‡ (Incremental Sharpe) çš„è¯„ä¼°å™¨
    éµå¾ª AlphaGen æ¡†æ¶ï¼šæŒ–æ˜èƒ½æå‡ç°æœ‰ç»„åˆè¡¨ç°çš„ååŒå› å­
    """

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.prediction_horizon = config.prediction_horizon
        self.bar_minutes = config.bar_minutes
        self.transaction_cost = getattr(config, 'transaction_cost', 0.0005)
        self.max_position = getattr(config, 'max_position', 0.1)
        self.sharpe_signal_lookback = getattr(config, 'sharpe_signal_lookback', 100)
        self.sharpe_signal_quantiles = getattr(config, 'sharpe_signal_quantiles', (0.3, 0.7))
        
        # å¹´åŒ–ç³»æ•°
        self.bars_per_year = 365 * 24 * 60 / max(self.bar_minutes, 1)
        
        # å¼•ç”¨ Combinerï¼Œä¸å†è‡ªå·±ç»´æŠ¤ Pool å’Œ Model
        self.combiner = None 

        logger.info(f"Synergy Evaluator initialized (Target: Incremental Sharpe)")

    def set_combiner(self, combiner):
        """æ³¨å…¥ Combiner å®ä¾‹"""
        self.combiner = combiner

    def calculate_ic(self, predictions: pd.Series, targets: pd.Series) -> float:
        """è®¡ç®— IC (ä»…ä½œä¸ºè§‚å¯ŸæŒ‡æ ‡ï¼Œä¸å‚ä¸ Reward)"""
        try:
            aligned = pd.DataFrame({'pred': predictions, 'target': targets}).dropna()
            if len(aligned) < 20: return 0.0
            if aligned['pred'].std() < 1e-8: return 0.0
            
            ic = aligned['pred'].corr(aligned['target'])
            return float(ic) if np.isfinite(ic) else 0.0
        except:
            return 0.0

    def calculate_turnover(self, predictions: pd.Series) -> float:
        """è®¡ç®—æ¢æ‰‹ç‡ (ç”¨äºæƒ©ç½šé¡¹)"""
        try:
            lookback = max(int(self.sharpe_signal_lookback), 20)
            if len(predictions) < lookback + 20: return 0.0
            
            # ç®€å•çš„åˆ†ä½æ•°ä¿¡å·ç”Ÿæˆ
            q_low, q_high = self.sharpe_signal_quantiles
            roll = predictions.rolling(window=lookback, min_periods=20)
            low, high = roll.quantile(q_low), roll.quantile(q_high)
            
            signals = pd.Series(0.0, index=predictions.index)
            signals[predictions > high] = 1.0
            signals[predictions < low] = -1.0
            signals = signals.fillna(0.0)
            
            # è®¡ç®—å¹³å‡æ¢æ‰‹
            turnover = signals.diff().abs().mean()
            return float(turnover) if np.isfinite(turnover) else 0.0
        except:
            return 0.0

    def calculate_rolling_sharpe_stability(self, predictions: pd.Series, targets: pd.Series,
                                          window_days: int = 3, stability_penalty: float = 1.5) -> float:
        """
        ğŸ”¥ è®¡ç®—æ»šåŠ¨å¤æ™®çš„ç¨³å®šæ€§å¾—åˆ†
        Score = Mean(Rolling_Sharpe) - lambda * Std(Rolling_Sharpe)

        æ³¨æ„ï¼šè¿™é‡Œçš„window_daysé»˜è®¤ä¸º3å¤©ï¼Œå¯¹åº”15åˆ†é’ŸKçº¿çº¦288æ ¹
        """
        try:
            # 1. è®¡ç®—å‡€å€¼æ›²çº¿ (Net Returns)
            net_returns = self._get_net_returns(predictions, targets)

            # ğŸ”¥ ä¿®å¤ï¼šéœ€è¦è¶³å¤Ÿçš„æ•°æ®æ‰èƒ½è®¡ç®—æ»šåŠ¨æŒ‡æ ‡
            bars_per_day = 24 * 60 / max(self.bar_minutes, 1)
            window_bars = max(int(window_days * bars_per_day), 50)  # è‡³å°‘50æ ¹Kçº¿
            min_required_bars = window_bars * 3  # è‡³å°‘3ä¸ªçª—å£çš„æ•°æ®

            if len(net_returns) < min_required_bars:
                return 0.0

            # 2. è®¡ç®—æ»šåŠ¨ Sharpe
            # æ»šåŠ¨è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
            rolling_mean = net_returns.rolling(window=window_bars, min_periods=window_bars//2).mean()
            rolling_std = net_returns.rolling(window=window_bars, min_periods=window_bars//2).std()

            # ğŸ”¥ ä¿®å¤ï¼šæ·»åŠ æ›´ä¸¥æ ¼çš„æ ‡å‡†å·®æ£€æŸ¥
            # å¦‚æœæ³¢åŠ¨ç‡å¤ªå°ï¼ˆæ¥è¿‘0ï¼‰ï¼Œè¯´æ˜ç­–ç•¥æ²¡æœ‰çœŸå®äº¤æ˜“æˆ–ä¿¡å·å¤ªå¼±
            rolling_std = rolling_std.replace(0, np.nan)

            # æ»šåŠ¨å¹´åŒ– Sharpe
            rolling_sharpe = (rolling_mean / (rolling_std + 1e-9)) * np.sqrt(self.bars_per_year)
            rolling_sharpe = rolling_sharpe.dropna()

            # ğŸ”¥ Clipæ»šåŠ¨Sharpeï¼šé˜²æ­¢å•ä¸ªçª—å£æ•°æ®å¼‚å¸¸å¯¼è‡´çˆ†ç‚¸
            # ä½†ä¸è¦clipå¾—å¤ªç´§ï¼ŒçœŸå®çš„ä¼˜ç§€ç­–ç•¥å¯èƒ½è¾¾åˆ°3-5
            rolling_sharpe = rolling_sharpe.clip(-5, 5)

            if len(rolling_sharpe) < 10:
                return 0.0

            # 3. è®¡ç®—ç¨³å®šæ€§å¾—åˆ†
            mean_s = rolling_sharpe.mean()
            std_s = rolling_sharpe.std()

            # ğŸ”¥ ä¿®å¤ï¼šå¦‚æœæ ‡å‡†å·®ä¸º0ï¼ˆæ‰€æœ‰çª—å£Sharpeç›¸åŒï¼‰ï¼Œè¿™å¾ˆå¯èƒ½æ˜¯æ•°æ®é—®é¢˜
            if std_s < 1e-6:
                # æƒ©ç½šè¿™ç§å¼‚å¸¸æƒ…å†µ
                return 0.0

            # æ ¸å¿ƒå…¬å¼ï¼šå¹³å‡è¡¨ç° - ä¸ç¡®å®šæ€§æƒ©ç½š
            stability_score = mean_s - stability_penalty * std_s

            # ğŸ”¥ æœ€ç»ˆclipï¼šåªé˜²æ­¢æ•°æ®å¼‚å¸¸å¯¼è‡´çš„çˆ†ç‚¸ï¼ˆNaN/Infï¼‰ï¼Œä¸é™åˆ¶åˆç†é«˜åˆ†
            # æ‰©å¤§åˆ°[-10, 10]ï¼Œä¸ºå¢é‡Sharpeç•™å‡ºè¶³å¤Ÿçš„åŒºåˆ†ç©ºé—´
            # è¿™æ ·å³ä½¿base_scoreè¾¾åˆ°5ï¼Œæ–°å› å­ä»å¯èƒ½å¸¦æ¥5çš„å¢é‡
            stability_score = np.clip(stability_score, -10.0, 10.0)

            return float(stability_score)

        except Exception as e:
            logger.warning(f"Error in stability calc: {e}")
            return 0.0

    def _get_net_returns(self, predictions: pd.Series, targets: pd.Series) -> pd.Series:
        """
        è¾…åŠ©å‡½æ•°ï¼šå°†å› å­é¢„æµ‹å€¼è½¬æ¢ä¸ºäº¤æ˜“ä¿¡å·ï¼Œå¹¶è®¡ç®—å‡€æ”¶ç›Š

        é€»è¾‘ï¼š
        1. ä½¿ç”¨æ»šåŠ¨z-scoreç”Ÿæˆä¿¡å·ï¼ˆ>1åšå¤šï¼Œ<-1åšç©ºï¼‰
        2. ä¿¡å· * æœªæ¥æ”¶ç›Š = æ€»æ”¶ç›Š
        3. å‡å»äº¤æ˜“æˆæœ¬
        """
        valid_idx = predictions.index.intersection(targets.index)
        if len(valid_idx) < 100:
            return pd.Series([], dtype=float)

        pred_val = predictions.loc[valid_idx]
        target_val = targets.loc[valid_idx]

        # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿predictionsæœ‰è¶³å¤Ÿçš„æ³¢åŠ¨ï¼Œå¦åˆ™z-scoreæ— æ„ä¹‰
        if pred_val.std() < 1e-10:
            # å› å­å€¼å‡ ä¹ä¸å˜ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆä¿¡å·
            return pd.Series([], dtype=float)

        lookback = max(int(self.sharpe_signal_lookback), 20)
        min_periods = min(lookback // 2, 20)

        # ç®€å•çš„æ»šåŠ¨ z-score ä¿¡å·
        roll = pred_val.rolling(window=lookback, min_periods=min_periods)
        mu = roll.mean()
        sigma = roll.std()

        # ğŸ”¥ ä¿®å¤ï¼šå¦‚æœsigmaä¸º0ï¼Œæ— æ³•è®¡ç®—z-score
        sigma = sigma.replace(0, np.nan)
        z_scores = (pred_val - mu) / (sigma + 1e-9)

        # ç”Ÿæˆäº¤æ˜“ä¿¡å·
        signals = pd.Series(0.0, index=pred_val.index)
        signals[z_scores > 1.0] = self.max_position
        signals[z_scores < -1.0] = -self.max_position

        # ğŸ”¥ å¦‚æœä¿¡å·å‡ ä¹ä¸å˜ï¼ˆæ ‡å‡†å·®<0.01ï¼‰ï¼Œè¯´æ˜ç­–ç•¥æ²¡æœ‰çœŸå®äº¤æ˜“
        if signals.std() < 0.01:
            return pd.Series([], dtype=float)

        # è®¡ç®—æ”¶ç›Š
        gross_returns = signals * target_val
        cost = signals.diff().abs().fillna(0.0) * self.transaction_cost
        net_returns = (gross_returns - cost).dropna()

        return net_returns

    def _get_incremental_sharpe(self, predictions: pd.Series, targets: pd.Series, use_val: bool) -> float:
        """
        ğŸ”¥ å®ç°å¢é‡è®¡ç®—ï¼šè°ƒç”¨ Combiner è¯•ç®— 'å‡å¦‚åŠ å…¥è¯¥å› å­ï¼ŒScore æå‡å¤šå°‘'
        """
        if self.combiner is None:
            # å¦‚æœæ²¡æœ‰ Combinerï¼Œé€€åŒ–ä¸ºå•å› å­è¯„ä¼°
            return self.calculate_rolling_sharpe_stability(predictions, targets)

        # è°ƒç”¨ Combiner çš„è¯•ç®—æ¨¡å¼ (Trial Mode)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å°† Val éƒ¨åˆ†ç•™ç©ºï¼Œå› ä¸º Reward é€šå¸¸åªçœ‹ Training set çš„å¢é‡
        result = self.combiner.evaluate_new_factor(
            alpha_info={},  # æš‚æ—¶ä¸éœ€è¦å…·ä½“ info
            train_factor=predictions,
            val_factor=pd.Series(dtype=float) 
        )
        
        return result.get('train_incremental_sharpe', 0.0)
    
    def evaluate(self, predictions: pd.Series, targets: pd.Series,
                 use_val: bool = False, add_to_history: bool = False,
                 is_single_factor: bool = True) -> Dict[str, float]:
        """
        è¯„ä¼°å‡½æ•°
        """
        # 1. åŸºç¡€æŒ‡æ ‡
        ic = self.calculate_ic(predictions, targets)
        
        # 2. è®¡ç®— Synergy Reward (å¢é‡ Sharpe Stability)
        synergy_reward = self._get_incremental_sharpe(predictions, targets, use_val)
        
        # 3. è®¡ç®—æ¢æ‰‹ç‡æƒ©ç½š
        turnover = self.calculate_turnover(predictions)
        penalty = 0.05 * max(0, turnover - 0.2)
        
        # 4. æœ€ç»ˆå¾—åˆ†
        final_score = synergy_reward - penalty
        
        # å•å› å­æœ¬èº«çš„ Sharpe (ä»…ä¾›å‚è€ƒ)
        single_sharpe = self.calculate_rolling_sharpe_stability(predictions, targets)

        result = {
            'ic': ic,
            'kl_divergence': 0.0,
            'avg_kl': 0.0,
            'avg_correlation': 0.0,
            'diversity_score': 1.0,
            'sharpe': single_sharpe,  
            'composite_score': final_score,  # ğŸ”¥ çœŸå®çš„ Reward
            'metric_type': 'incremental_sharpe_stability'
        }

        # 5. çŠ¶æ€æ›´æ–° (Commit Mode)
        if add_to_history and self.combiner is not None:
            self.add_factor(predictions, use_val=use_val, targets=targets)

        return result

    def add_factor(self, predictions: pd.Series, use_val: bool = False, targets: pd.Series = None):
        """
        æ›´æ–°å› å­æ±  - å§”æ‰˜ç»™ Combiner
        """
        if self.combiner:
            # åœ¨è¿™é‡Œæˆ‘ä»¬å‡è®¾å¤–éƒ¨å¾ªç¯æˆ–è€… Combiner å·²ç»å¤„ç†å¥½äº† targets çš„è®¾ç½®
            # è¿™é‡Œçš„ add_factor åªæ˜¯é€šçŸ¥ Combiner ç¡®è®¤é‡‡çº³å½“å‰å› å­
            # æ³¨æ„ï¼šå› ä¸º evaluate æ—¶ä¼ å…¥çš„æ˜¯ predictionsï¼Œè¿™é‡Œæˆ‘ä»¬å†æ¬¡ä¼ å…¥
            # å®é™…å·¥ç¨‹ä¸­å¯ä»¥ç”¨ cache ä¼˜åŒ–ï¼Œä½†è¿™é‡Œä¸ºäº†é€»è¾‘æ¸…æ™°ç›´æ¥ä¼ é€’
            self.combiner.add_alpha_and_optimize(
                alpha_info={}, 
                train_factor=predictions,
                val_factor=pd.Series(dtype=float) # Val æš‚ä¸ç”¨äºæ›´æ–°æƒé‡é€»è¾‘
            )

    # åºŸå¼ƒæ–¹æ³•çš„å­˜æ ¹
    def calculate_kl_divergence(self, *args, **kwargs): return 0.0
    def get_average_kl(self, *args, **kwargs): return 0.0
    def add_kl_to_history(self, *args, **kwargs): pass
    def calculate_avg_correlation(self, *args, **kwargs): return 0.0
    # å…¼å®¹æ€§å­˜æ ¹ï¼šå¦‚æœå¤–éƒ¨ä»£ç è°ƒç”¨äº†è¿™ä¸ªå±æ€§ï¼Œè¿”å›ç©ºåˆ—è¡¨
    @property
    def historical_factors_train(self): return []
    @property
    def historical_factors_val(self): return []