"""
æ›´æ–°åçš„ ICDiversityEvaluator - ä½¿ç”¨ç»Ÿä¸€çš„ä¿¡å·ç”Ÿæˆå’Œè¯„ä¼°é€»è¾‘
"""

import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Optional
from config import TrainingConfig
from signals import SignalGenerator, PerformanceEvaluator

logger = logging.getLogger(__name__)


class ICDiversityEvaluator:
    """
    åŸºäºç»„åˆå¢é‡å¤æ™®æ¯”ç‡ (Incremental Sharpe) çš„è¯„ä¼°å™¨
    éµå¾ª AlphaGen æ¡†æ¶ï¼šæŒ–æ˜èƒ½æå‡ç°æœ‰ç»„åˆè¡¨ç°çš„ååŒå› å­
    ğŸ†• æ›´æ–°:
    ----
    - ä½¿ç”¨ç»Ÿä¸€çš„ SignalGenerator ç”Ÿæˆä¿¡å·
    - ä½¿ç”¨ç»Ÿä¸€çš„ PerformanceEvaluator è®¡ç®—æŒ‡æ ‡
    - è®­ç»ƒå’Œå›æµ‹é€»è¾‘å®Œå…¨ä¸€è‡´
    """

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.prediction_horizon = config.prediction_horizon
        self.bar_minutes = config.bar_minutes
        self.transaction_cost = getattr(config, 'transaction_cost', 0.0005)
        self.max_position = getattr(config, 'max_position', 0.1)
        self.sharpe_signal_lookback = getattr(config, 'sharpe_signal_lookback', 100)
        self.sharpe_signal_quantiles = getattr(config, 'sharpe_signal_quantiles', (0.3, 0.7))
        
        # å¹´åŒ–ç³»æ•°
        self.bars_per_year = 365 * 24 * 60 / self.bar_minutes
        
        # ğŸ†• åˆ›å»ºç»Ÿä¸€çš„ä¿¡å·ç”Ÿæˆå™¨
        self.signal_generator = SignalGenerator(
            max_position=self.max_position,
            lookback=self.sharpe_signal_lookback,
            q_low=self.sharpe_signal_quantiles[0],
            q_high=self.sharpe_signal_quantiles[1],
            neutral_fraction=0.1,  # ä¸­æ€§åŒºåŸŸ1/10ä»“ä½
            min_periods=20
        )
        
        # ğŸ†• åˆ›å»ºç»Ÿä¸€çš„æ€§èƒ½è¯„ä¼°å™¨
        self.performance_evaluator = PerformanceEvaluator(
            prediction_horizon=self.prediction_horizon,
            bar_minutes=self.bar_minutes,
            transaction_cost=self.transaction_cost,
            signal_generator=self.signal_generator
        )
        
        # å¼•ç”¨ Combinerï¼Œä¸å†è‡ªå·±ç»´æŠ¤ Pool å’Œ Model
        self.combiner = None 

        logger.info(f"Synergy Evaluator initialized (Target: Incremental Sharpe)")
        logger.info(f"  - Signal Generator: max_pos={self.max_position}, "
                   f"lookback={self.sharpe_signal_lookback}")

    def set_combiner(self, combiner):
        """æ³¨å…¥ Combiner å®ä¾‹"""
        self.combiner = combiner

    def calculate_ic(self, predictions: pd.Series, targets: pd.Series) -> float:
        """
        è®¡ç®— IC (ä»…ä½œä¸ºè§‚å¯ŸæŒ‡æ ‡ï¼Œä¸å‚ä¸ Reward)
        å§”æ‰˜ç»™ PerformanceEvaluator
        """
        return self.performance_evaluator.calculate_ic(predictions, targets)

    def calculate_turnover(self, predictions: pd.Series) -> float:
        """
        è®¡ç®—æ¢æ‰‹ç‡ (ç”¨äºæƒ©ç½šé¡¹)
        ğŸ†• ä½¿ç”¨ä¿¡å·ç”Ÿæˆå™¨è®¡ç®—
        """
        if len(predictions) < self.sharpe_signal_lookback + 20:
            return 0.0
        
        # ç”Ÿæˆä¿¡å·
        signals = self.signal_generator.generate_signals(predictions)
        
        # è®¡ç®—æ¢æ‰‹ç‡
        turnover = self.signal_generator.calculate_turnover(signals)
        
        return turnover

    def calculate_rolling_sharpe_stability(self, 
                                          predictions: pd.Series, 
                                          targets: pd.Series,
                                          window_days: int = 3, 
                                          stability_penalty: float = 1.5) -> float:
        """
        è®¡ç®—æ»šåŠ¨å¤æ™®çš„ç¨³å®šæ€§å¾—åˆ†
        ğŸ†• å§”æ‰˜ç»™ PerformanceEvaluator
        
        Score = Mean(Rolling_Sharpe) - lambda * Std(Rolling_Sharpe)
        """
        return self.performance_evaluator.calculate_rolling_sharpe_stability(
            predictions, targets, window_days, stability_penalty
        )

    def _get_incremental_sharpe(self, predictions: pd.Series, targets: pd.Series, use_val: bool) -> float:
        """
        ğŸ”¥ å®ç°å¢é‡è®¡ç®—ï¼šè°ƒç”¨ Combiner è¯•ç®— 'å‡å¦‚åŠ å…¥è¯¥å› å­ï¼ŒScore æå‡å¤šå°‘'
        """
        if self.combiner is None:
            # å¦‚æœæ²¡æœ‰ Combinerï¼Œé€€åŒ–ä¸ºå•å› å­è¯„ä¼°
            score = self.calculate_rolling_sharpe_stability(predictions, targets)
            # ğŸ”¥ ä¿®å¤ï¼šå¦‚æœè®¡ç®—å¤±è´¥ï¼Œè¿”å›0
            return score if score is not None else 0.0

        # è°ƒç”¨ Combiner çš„è¯•ç®—æ¨¡å¼ (Trial Mode)
        result = self.combiner.evaluate_new_factor(
            alpha_info={},  # æš‚æ—¶ä¸éœ€è¦å…·ä½“ info
            train_factor=predictions,
            val_factor=pd.Series(dtype=float) 
        )
        
        return result.get('train_incremental_sharpe', 0.0)
    
    def evaluate(self, predictions: pd.Series, targets: pd.Series,
                 use_val: bool = False, add_to_history: bool = False,
                 is_single_factor: bool = True) -> Dict[str, float]:
        """
        è¯„ä¼°å‡½æ•°
        ğŸ†• ä½¿ç”¨ç»Ÿä¸€çš„æ€§èƒ½è¯„ä¼°å™¨
        """
        # 1. åŸºç¡€æŒ‡æ ‡
        ic = self.calculate_ic(predictions, targets)
        
        # 2. è®¡ç®— Synergy Reward (å¢é‡ Sharpe Stability)
        synergy_reward = self._get_incremental_sharpe(predictions, targets, use_val)
        
        # 3. è®¡ç®—æ¢æ‰‹ç‡æƒ©ç½š (ä½¿ç”¨ç»Ÿä¸€çš„ä¿¡å·ç”Ÿæˆå™¨)
        turnover = self.calculate_turnover(predictions)
        penalty = 0.05 * max(0, turnover - 0.2)
        
        # 4. æœ€ç»ˆå¾—åˆ†
        final_score = synergy_reward - penalty
        
        # å•å› å­æœ¬èº«çš„ Sharpe (ä»…ä¾›å‚è€ƒ)
        single_sharpe = self.calculate_rolling_sharpe_stability(predictions, targets)
        # ğŸ”¥ ä¿®å¤ï¼šå¦‚æœè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨0
        if single_sharpe is None:
            single_sharpe = 0.0

        result = {
            'ic': ic,
            'kl_divergence': 0.0,
            'avg_kl': 0.0,
            'avg_correlation': 0.0,
            'diversity_score': 1.0,
            'sharpe': single_sharpe,  
            'composite_score': final_score,  # ğŸ”¥ çœŸå®çš„ Reward
            'metric_type': 'incremental_sharpe_stability',
            'turnover': turnover,
        }

        # 5. çŠ¶æ€æ›´æ–° (Commit Mode)
        if add_to_history and self.combiner is not None:
            self.add_factor(predictions, use_val=use_val, targets=targets)

        return result

    def add_factor(self, predictions: pd.Series, use_val: bool = False, targets: pd.Series = None):
        """
        æ›´æ–°å› å­æ±  - å§”æ‰˜ç»™ Combiner
        """
        if self.combiner:
            self.combiner.add_alpha_and_optimize(
                alpha_info={}, 
                train_factor=predictions,
                val_factor=pd.Series(dtype=float)
            )

    # åºŸå¼ƒæ–¹æ³•çš„å­˜æ ¹
    def calculate_kl_divergence(self, *args, **kwargs): return 0.0
    def get_average_kl(self, *args, **kwargs): return 0.0
    def add_kl_to_history(self, *args, **kwargs): pass
    def calculate_avg_correlation(self, *args, **kwargs): return 0.0
    
    # å…¼å®¹æ€§å­˜æ ¹ï¼šå¦‚æœå¤–éƒ¨ä»£ç è°ƒç”¨äº†è¿™ä¸ªå±æ€§ï¼Œè¿”å›ç©ºåˆ—è¡¨
    @property
    def historical_factors_train(self): return []
    @property
    def historical_factors_val(self): return []