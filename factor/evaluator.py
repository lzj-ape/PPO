import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Optional
from config import TrainingConfig

logger = logging.getLogger(__name__)

class ICDiversityEvaluator:
    """
    åŸºäºç»„åˆå¢é‡å¤æ™®æ¯”ç‡ (Incremental Sharpe) çš„è¯„ä¼°å™¨
    éµå¾ª AlphaGen æ¡†æ¶ï¼šæŒ–æ˜èƒ½æå‡ç°æœ‰ç»„åˆè¡¨ç°çš„ååŒå› å­
    """

    def __init__(self, config: TrainingConfig):
        self.config = config
        self.prediction_horizon = config.prediction_horizon
        self.bar_minutes = config.bar_minutes
        self.transaction_cost = getattr(config, 'transaction_cost', 0.0005)
        self.max_position = getattr(config, 'max_position', 0.1)
        self.sharpe_signal_lookback = getattr(config, 'sharpe_signal_lookback', 100)
        self.sharpe_signal_quantiles = getattr(config, 'sharpe_signal_quantiles', (0.3, 0.7))
        
        # å¹´åŒ–ç³»æ•°
        self.bars_per_year = 365 * 24 * 60 / max(self.bar_minutes, 1)
        
        # å¼•ç”¨ Combinerï¼Œä¸å†è‡ªå·±ç»´æŠ¤ Pool å’Œ Model
        self.combiner = None 

        logger.info(f"Synergy Evaluator initialized (Target: Incremental Sharpe)")

    def set_combiner(self, combiner):
        """æ³¨å…¥ Combiner å®ä¾‹"""
        self.combiner = combiner

    def calculate_ic(self, predictions: pd.Series, targets: pd.Series) -> float:
        """è®¡ç®— IC (ä»…ä½œä¸ºè§‚å¯ŸæŒ‡æ ‡ï¼Œä¸å‚ä¸ Reward)"""
        try:
            aligned = pd.DataFrame({'pred': predictions, 'target': targets}).dropna()
            if len(aligned) < 20: return 0.0
            if aligned['pred'].std() < 1e-8: return 0.0
            
            ic = aligned['pred'].corr(aligned['target'])
            return float(ic) if np.isfinite(ic) else 0.0
        except:
            return 0.0

    def calculate_turnover(self, predictions: pd.Series) -> float:
        """è®¡ç®—æ¢æ‰‹ç‡ (ç”¨äºæƒ©ç½šé¡¹)"""
        try:
            lookback = max(int(self.sharpe_signal_lookback), 20)
            if len(predictions) < lookback + 20: return 0.0
            
            # ç®€å•çš„åˆ†ä½æ•°ä¿¡å·ç”Ÿæˆ
            q_low, q_high = self.sharpe_signal_quantiles
            roll = predictions.rolling(window=lookback, min_periods=20)
            low, high = roll.quantile(q_low), roll.quantile(q_high)
            
            signals = pd.Series(0.0, index=predictions.index)
            signals[predictions > high] = 1.0
            signals[predictions < low] = -1.0
            signals = signals.fillna(0.0)
            
            # è®¡ç®—å¹³å‡æ¢æ‰‹
            turnover = signals.diff().abs().mean()
            return float(turnover) if np.isfinite(turnover) else 0.0
        except:
            return 0.0

    def calculate_rolling_sharpe_stability(self, predictions: pd.Series, targets: pd.Series, 
                                          window_days: int = 90, stability_penalty: float = 1.5) -> float:
        """
        ğŸ”¥ è®¡ç®—æ»šåŠ¨å¤æ™®çš„ç¨³å®šæ€§å¾—åˆ†
        Score = Mean(Rolling_Sharpe) - lambda * Std(Rolling_Sharpe)
        """
        try:
            # 1. è®¡ç®—å‡€å€¼æ›²çº¿ (Net Returns)
            net_returns = self._get_net_returns(predictions, targets)
            
            if len(net_returns) < window_days * 2: return 0.0
            
            # 2. è®¡ç®—æ»šåŠ¨ Sharpe
            bars_per_day = 24 * 60 / max(self.bar_minutes, 1)
            window_bars = int(window_days * bars_per_day)
            
            # æ»šåŠ¨è®¡ç®—å‡å€¼å’Œæ ‡å‡†å·®
            rolling_mean = net_returns.rolling(window=window_bars).mean()
            rolling_std = net_returns.rolling(window=window_bars).std()
            
            # æ»šåŠ¨å¹´åŒ– Sharpe
            rolling_sharpe = (rolling_mean / (rolling_std + 1e-9)) * np.sqrt(self.bars_per_year)
            rolling_sharpe = rolling_sharpe.dropna()
            
            # å‰”é™¤æç«¯å€¼
            rolling_sharpe = rolling_sharpe.clip(-5, 5)
            
            if len(rolling_sharpe) < 10: return 0.0
            
            # 3. è®¡ç®—ç¨³å®šæ€§å¾—åˆ†
            mean_s = rolling_sharpe.mean()
            std_s = rolling_sharpe.std()
            
            # æ ¸å¿ƒå…¬å¼ï¼šå¹³å‡è¡¨ç° - ä¸ç¡®å®šæ€§æƒ©ç½š
            stability_score = mean_s - stability_penalty * std_s
            
            return float(stability_score)
            
        except Exception as e:
            # logger.warning(f"Error in stability calc: {e}")
            return 0.0

    def _get_net_returns(self, predictions: pd.Series, targets: pd.Series) -> pd.Series:
        """è¾…åŠ©å‡½æ•°ï¼šæå–å‡€å€¼æ”¶ç›Šé€»è¾‘"""
        valid_idx = predictions.index.intersection(targets.index)
        if len(valid_idx) < 100: return pd.Series([], dtype=float)
        
        pred_val = predictions.loc[valid_idx]
        target_val = targets.loc[valid_idx]
        
        lookback = max(int(self.sharpe_signal_lookback), 20)
        min_periods = min(lookback, 20)
        
        # ç®€å•çš„æ»šåŠ¨ z-score ä¿¡å·
        roll = pred_val.rolling(window=lookback, min_periods=min_periods)
        mu = roll.mean()
        sigma = roll.std() + 1e-9
        z_scores = (pred_val - mu) / sigma
        
        signals = pd.Series(0.0, index=pred_val.index)
        signals[z_scores > 1.0] = self.max_position
        signals[z_scores < -1.0] = -self.max_position
        
        gross_returns = signals * target_val
        cost = signals.diff().abs().fillna(0.0) * self.transaction_cost
        return (gross_returns - cost).dropna()

    def _get_incremental_sharpe(self, predictions: pd.Series, targets: pd.Series, use_val: bool) -> float:
        """
        ğŸ”¥ å®ç°å¢é‡è®¡ç®—ï¼šè°ƒç”¨ Combiner è¯•ç®— 'å‡å¦‚åŠ å…¥è¯¥å› å­ï¼ŒScore æå‡å¤šå°‘'
        """
        if self.combiner is None:
            # å¦‚æœæ²¡æœ‰ Combinerï¼Œé€€åŒ–ä¸ºå•å› å­è¯„ä¼°
            return self.calculate_rolling_sharpe_stability(predictions, targets)

        # è°ƒç”¨ Combiner çš„è¯•ç®—æ¨¡å¼ (Trial Mode)
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å°† Val éƒ¨åˆ†ç•™ç©ºï¼Œå› ä¸º Reward é€šå¸¸åªçœ‹ Training set çš„å¢é‡
        result = self.combiner.evaluate_new_factor(
            alpha_info={},  # æš‚æ—¶ä¸éœ€è¦å…·ä½“ info
            train_factor=predictions,
            val_factor=pd.Series(dtype=float) 
        )
        
        return result.get('train_incremental_sharpe', 0.0)
    
    def evaluate(self, predictions: pd.Series, targets: pd.Series,
                 use_val: bool = False, add_to_history: bool = False,
                 is_single_factor: bool = True) -> Dict[str, float]:
        """
        è¯„ä¼°å‡½æ•°
        """
        # 1. åŸºç¡€æŒ‡æ ‡
        ic = self.calculate_ic(predictions, targets)
        
        # 2. è®¡ç®— Synergy Reward (å¢é‡ Sharpe Stability)
        synergy_reward = self._get_incremental_sharpe(predictions, targets, use_val)
        
        # 3. è®¡ç®—æ¢æ‰‹ç‡æƒ©ç½š
        turnover = self.calculate_turnover(predictions)
        penalty = 0.05 * max(0, turnover - 0.2)
        
        # 4. æœ€ç»ˆå¾—åˆ†
        final_score = synergy_reward - penalty
        
        # å•å› å­æœ¬èº«çš„ Sharpe (ä»…ä¾›å‚è€ƒ)
        single_sharpe = self.calculate_rolling_sharpe_stability(predictions, targets)

        result = {
            'ic': ic,
            'kl_divergence': 0.0,
            'avg_kl': 0.0,
            'avg_correlation': 0.0,
            'diversity_score': 1.0,
            'sharpe': single_sharpe,  
            'composite_score': final_score,  # ğŸ”¥ çœŸå®çš„ Reward
            'metric_type': 'incremental_sharpe_stability'
        }

        # 5. çŠ¶æ€æ›´æ–° (Commit Mode)
        if add_to_history and self.combiner is not None:
            self.add_factor(predictions, use_val=use_val, targets=targets)

        return result

    def add_factor(self, predictions: pd.Series, use_val: bool = False, targets: pd.Series = None):
        """
        æ›´æ–°å› å­æ±  - å§”æ‰˜ç»™ Combiner
        """
        if self.combiner:
            # åœ¨è¿™é‡Œæˆ‘ä»¬å‡è®¾å¤–éƒ¨å¾ªç¯æˆ–è€… Combiner å·²ç»å¤„ç†å¥½äº† targets çš„è®¾ç½®
            # è¿™é‡Œçš„ add_factor åªæ˜¯é€šçŸ¥ Combiner ç¡®è®¤é‡‡çº³å½“å‰å› å­
            # æ³¨æ„ï¼šå› ä¸º evaluate æ—¶ä¼ å…¥çš„æ˜¯ predictionsï¼Œè¿™é‡Œæˆ‘ä»¬å†æ¬¡ä¼ å…¥
            # å®é™…å·¥ç¨‹ä¸­å¯ä»¥ç”¨ cache ä¼˜åŒ–ï¼Œä½†è¿™é‡Œä¸ºäº†é€»è¾‘æ¸…æ™°ç›´æ¥ä¼ é€’
            self.combiner.add_alpha_and_optimize(
                alpha_info={}, 
                train_factor=predictions,
                val_factor=pd.Series(dtype=float) # Val æš‚ä¸ç”¨äºæ›´æ–°æƒé‡é€»è¾‘
            )

    # åºŸå¼ƒæ–¹æ³•çš„å­˜æ ¹
    def calculate_kl_divergence(self, *args, **kwargs): return 0.0
    def get_average_kl(self, *args, **kwargs): return 0.0
    def add_kl_to_history(self, *args, **kwargs): pass
    def calculate_avg_correlation(self, *args, **kwargs): return 0.0
    # å…¼å®¹æ€§å­˜æ ¹ï¼šå¦‚æœå¤–éƒ¨ä»£ç è°ƒç”¨äº†è¿™ä¸ªå±æ€§ï¼Œè¿”å›ç©ºåˆ—è¡¨
    @property
    def historical_factors_train(self): return []
    @property
    def historical_factors_val(self): return []