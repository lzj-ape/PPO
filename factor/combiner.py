import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Tuple, Optional
from sklearn.linear_model import Ridge
from config import TrainingConfig
# æ³¨æ„ï¼šè¿™é‡Œä¸å†å¯¼å…¥ ICDiversityEvaluator ä»¥é¿å…å¾ªç¯å¯¼å…¥
# æˆ‘ä»¬å°†åœ¨è¿è¡Œæ—¶é€šè¿‡ set_evaluator æ³¨å…¥å®ä¾‹

logger = logging.getLogger(__name__)

class ImprovedCombinationModel:
    """
    åŸºäº Ridge å›å½’çš„ç»„åˆæ¨¡å‹
    æ ¸å¿ƒï¼šReward = Incremental Rolling Sharpe Stability Score
    """

    def __init__(self, config: TrainingConfig, max_alpha_count: int = 15):
        self.config = config
        self.max_alpha_count = max_alpha_count
        self.combiner_type = config.combiner_type  # æ·»åŠ combiner_typeå±æ€§

        # å› å­æ± ä¿¡æ¯
        self.alpha_pool: List[Dict] = []

        # å› å­æ•°æ®çŸ©é˜µ
        self.train_matrix: Optional[pd.DataFrame] = None
        self.val_matrix: Optional[pd.DataFrame] = None

        # ç›®æ ‡å€¼
        self.train_target: Optional[pd.Series] = None
        self.val_target: Optional[pd.Series] = None

        # æ¨¡å‹ä¸çŠ¶æ€
        self.ridge_model = Ridge(alpha=1.0, fit_intercept=False)
        self.current_weights: Optional[np.ndarray] = None
        self.evaluator = None # ç±»å‹: ICDiversityEvaluator

        # ç¼“å­˜å½“å‰çš„åŸºå‡†åˆ†æ•°
        self.base_train_score = 0.0
        self.base_val_score = 0.0

        # Rolling Sharpe çš„å‚æ•°
        self.rolling_window_days = getattr(config, 'rolling_window_days', 3)
        self.stability_penalty = getattr(config, 'stability_penalty', 1.5)

        # ğŸ”¥ æ–°å¢ï¼šè®°å½•æ¯ä¸ªå› å­çš„å¢é‡è´¡çŒ®å†å²
        self.factor_contributions: List[float] = []

    def set_evaluator(self, evaluator):
        self.evaluator = evaluator

    def set_targets(self, train_target: pd.Series, val_target: pd.Series):
        self.train_target = train_target
        self.val_target = val_target

    def _align_and_clean(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:
        """å¯¹é½ç‰¹å¾å’Œç›®æ ‡ï¼Œå¹¶å¤„ç† NaN/Inf"""
        # 1. ç¡®ä¿ç´¢å¼•äº¤é›†
        valid_idx = X.index.intersection(y.index)
        
        # 2. ç­›é€‰å¹¶å¡«å……
        X_clean = X.loc[valid_idx].fillna(0.0).replace([np.inf, -np.inf], 0.0)
        y_clean = y.loc[valid_idx].fillna(0.0)
        
        return X_clean, y_clean

    def evaluate_new_factor(self, alpha_info: Dict,
                           train_factor: pd.Series, val_factor: pd.Series) -> Dict:
        """
        ğŸ”¥ è¯•ç®—æ¨¡å¼ (Trial Mode): ä»…è®¡ç®—å¢é‡ç¨³å®šæ€§ï¼Œä¸ä¿®æ”¹æ± å­å’Œæ¨¡å‹çŠ¶æ€ã€‚
        """
        if self.evaluator is None or self.train_target is None:
            return {'train_incremental_sharpe': 0.0, 'train_stats': {'sharpe': 0.0}, 'val_stats': {'sharpe': 0.0}}

        # 1. å¯¹é½æ–°å› å­æ•°æ®åˆ° Target ç´¢å¼• (å…³é”®ä¿®å¤ï¼šé˜²æ­¢ç´¢å¼•é”™ä½)
        train_factor_aligned = train_factor.reindex(self.train_target.index).fillna(0.0)

        # 2. æ„é€ ä¸´æ—¶è®­ç»ƒçŸ©é˜µ
        if self.train_matrix is None or len(self.alpha_pool) == 0:
            # Case A: æ± å­ä¸ºç©º
            temp_train_X = train_factor_aligned.to_frame(name='new')
        else:
            # Case B: æ‹¼æ¥ç°æœ‰çŸ©é˜µ (ä½¿ç”¨ reindex ç¡®ä¿ train_matrix ä¹Ÿå¯¹é½)
            # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†æ•ˆç‡ï¼Œåœ¨å®é™…å¤§è§„æ¨¡ç”Ÿäº§ä¸­åº”å°½é‡é¿å…æ¯æ¬¡éƒ½ concat DataFrame
            # ä½†ä¸ºäº†ä»£ç æ¸…æ™°åº¦ï¼Œä¿æŒ concat
            current_X = self.train_matrix.reindex(self.train_target.index).fillna(0.0)
            temp_train_X = pd.concat([current_X, train_factor_aligned.rename('new')], axis=1)

        # 3. ğŸ”¥ åˆ›å»ºä¸´æ—¶æ¨¡å‹ï¼ˆä¸æ±¡æŸ“ self.ridge_modelï¼‰
        X_train, y_train = self._align_and_clean(temp_train_X, self.train_target)

        if len(X_train) < 100:
            return {'train_incremental_sharpe': 0.0, 'train_stats': {'sharpe': 0.0}, 'val_stats': {'sharpe': 0.0}}

        try:
            # ğŸ”¥ ä½¿ç”¨ä¸´æ—¶æ¨¡å‹è¿›è¡Œæ‹Ÿåˆï¼Œé¿å…æ±¡æŸ“ä¸»æ¨¡å‹çŠ¶æ€
            from sklearn.linear_model import Ridge
            temp_model = Ridge(alpha=1.0, fit_intercept=False)
            temp_model.fit(X_train.values, y_train.values)

            # é¢„æµ‹ç»„åˆæ”¶ç›Š
            train_pred_vals = temp_model.predict(X_train.values)
            train_pred_series = pd.Series(train_pred_vals, index=X_train.index)

            # è®¡ç®—æ–°çš„ Stability Score
            new_train_score = self.evaluator.calculate_rolling_sharpe_stability(
                train_pred_series, y_train,
                window_days=self.rolling_window_days, stability_penalty=self.stability_penalty
            )

            # 4. è®¡ç®—å¢é‡ (Reward)
            incremental_score = new_train_score - self.base_train_score

            return {
                'train_incremental_sharpe': incremental_score,
                'train_stats': {'sharpe': new_train_score, 'composite_score': new_train_score},
                # Val stats æš‚ç•¥ï¼Œä»¥èŠ‚çœè®¡ç®—èµ„æº
                'val_stats': {'sharpe': 0.0, 'composite_score': 0.0},
            }
        except Exception as e:
            logger.error(f"Combiner trial failed: {e}")
            return {'train_incremental_sharpe': 0.0, 'train_stats': {'sharpe': 0.0}, 'val_stats': {'sharpe': 0.0}}

    def add_alpha_and_optimize(self, alpha_info: Dict,
                              train_factor: pd.Series, val_factor: pd.Series) -> Dict:
        """
        ğŸ”¥ æäº¤æ¨¡å¼ (Commit Mode): çœŸæ­£å°†å› å­åŠ å…¥æ± å­ï¼Œå¹¶æ›´æ–°åŸºå‡†çŠ¶æ€ã€‚
        """
        if self.train_target is None:
            return {}

        factor_name = f"alpha_{len(self.alpha_pool)}"

        # ğŸ”¥ è®°å½•æ·»åŠ å‰çš„åˆ†æ•°ï¼Œç”¨äºè®¡ç®—å¢é‡è´¡çŒ®
        score_before_add = self.base_train_score

        # 1. æ›´æ–°å› å­æ± å…ƒæ•°æ®
        self.alpha_pool.append(alpha_info)

        # 2. æ›´æ–°æ•°æ®çŸ©é˜µ (å¼ºåˆ¶å¯¹é½)
        train_factor_aligned = train_factor.reindex(self.train_target.index).fillna(0.0)
        if self.val_target is not None:
            val_factor_aligned = val_factor.reindex(self.val_target.index).fillna(0.0)
        else:
            val_factor_aligned = pd.DataFrame()

        if self.train_matrix is None:
            self.train_matrix = train_factor_aligned.to_frame(name=factor_name)
            if not val_factor_aligned.empty:
                self.val_matrix = val_factor_aligned.to_frame(name=factor_name)
        else:
            self.train_matrix[factor_name] = train_factor_aligned
            if self.val_matrix is not None and not val_factor_aligned.empty:
                self.val_matrix[factor_name] = val_factor_aligned

        # 3. é‡æ–°æ‹ŸåˆåŸºå‡†æ¨¡å‹
        X_train, y_train = self._align_and_clean(self.train_matrix, self.train_target)

        if len(X_train) > 100:
            self.ridge_model.fit(X_train.values, y_train.values)
            # ğŸ”¥ ä¿®å¤ï¼šç¡®ä¿coef_æ˜¯ä¸€ç»´æ•°ç»„
            if hasattr(self.ridge_model.coef_, 'flatten'):
                self.current_weights = self.ridge_model.coef_.flatten()
            else:
                self.current_weights = np.atleast_1d(self.ridge_model.coef_)

            # 4. ğŸ”¥ æ›´æ–°åŸºå‡† Rolling Stability Score
            train_pred_vals = self.ridge_model.predict(X_train.values)
            train_pred_series = pd.Series(train_pred_vals, index=X_train.index)

            self.base_train_score = self.evaluator.calculate_rolling_sharpe_stability(
                train_pred_series, y_train,
                window_days=self.rolling_window_days, stability_penalty=self.stability_penalty
            )

            # Val Score Update (å¦‚æœéœ€è¦)
            if self.val_matrix is not None and self.val_target is not None:
                X_val, y_val = self._align_and_clean(self.val_matrix, self.val_target)
                if len(X_val) > 50:
                    val_pred = self.ridge_model.predict(X_val.values)
                    self.base_val_score = self.evaluator.calculate_rolling_sharpe_stability(
                        pd.Series(val_pred, index=X_val.index), y_val,
                        window_days=self.rolling_window_days, stability_penalty=self.stability_penalty
                    )

        # ğŸ”¥ è®°å½•è¯¥å› å­çš„å¢é‡è´¡çŒ®
        incremental_contribution = self.base_train_score - score_before_add
        self.factor_contributions.append(incremental_contribution)

        # 5. æ·˜æ±°æœ€å·®å› å­ (å¦‚æœæ± å­æ»¡äº†)
        if len(self.alpha_pool) > self.max_alpha_count:
            self._prune_factor()

        return {
            'pool_size': len(self.alpha_pool),
            'current_train_score': self.base_train_score,
            'current_val_score': self.base_val_score,
            'incremental_contribution': incremental_contribution
        }

    def _prune_factor(self):
        """
        ğŸ”¥ æ”¹è¿›çš„æ·˜æ±°æœºåˆ¶ï¼šç§»é™¤å¢é‡è´¡çŒ®æœ€å°çš„å› å­
        ä¼˜å…ˆçº§ï¼š
        1. ç§»é™¤è´Ÿè´¡çŒ®æœ€å¤§çš„å› å­
        2. å¦‚æœéƒ½æ˜¯æ­£è´¡çŒ®ï¼Œç§»é™¤è´¡çŒ®æœ€å°çš„å› å­
        3. å¦‚æœæ²¡æœ‰è´¡çŒ®è®°å½•ï¼Œå›é€€åˆ°æƒé‡æ·˜æ±°
        """
        if len(self.alpha_pool) <= self.max_alpha_count:
            return

        # æ–¹æ³•1: åŸºäºå¢é‡è´¡çŒ®æ·˜æ±°
        if len(self.factor_contributions) == len(self.alpha_pool):
            # æ‰¾åˆ°è´¡çŒ®æœ€å°ï¼ˆå¯èƒ½æ˜¯è´Ÿå€¼ï¼‰çš„å› å­
            min_contribution_idx = np.argmin(self.factor_contributions)
            logger.info(f"Pruning factor {min_contribution_idx} with contribution {self.factor_contributions[min_contribution_idx]:.4f}")
        # æ–¹æ³•2: å›é€€åˆ°æƒé‡æ·˜æ±°ï¼ˆå…¼å®¹æ€§ï¼‰
        elif self.current_weights is not None:
            min_contribution_idx = np.argmin(np.abs(self.current_weights))
            logger.info(f"Pruning factor {min_contribution_idx} with weight {self.current_weights[min_contribution_idx]:.4f} (fallback mode)")
        else:
            logger.warning("Cannot prune: no contributions or weights available")
            return

        # è®°å½•å¹¶ç§»é™¤
        col_to_drop = self.train_matrix.columns[min_contribution_idx]

        # ç§»é™¤ Metadata
        self.alpha_pool.pop(min_contribution_idx)
        self.factor_contributions.pop(min_contribution_idx)

        # æ›´æ–°çŸ©é˜µ
        self.train_matrix.drop(columns=[col_to_drop], inplace=True)
        if self.val_matrix is not None and col_to_drop in self.val_matrix.columns:
            self.val_matrix.drop(columns=[col_to_drop], inplace=True)

        # æ›´æ–°æƒé‡æ•°ç»„
        if self.current_weights is not None:
            self.current_weights = np.delete(self.current_weights, min_contribution_idx)

        # é‡æ–°æ‹Ÿåˆä»¥ä¿æŒ base_score å‡†ç¡®
        X_train, y_train = self._align_and_clean(self.train_matrix, self.train_target)
        if len(X_train) > 100:
            self.ridge_model.fit(X_train.values, y_train.values)
            self.current_weights = self.ridge_model.coef_

            # æ›´æ–° Base Score
            train_pred = self.ridge_model.predict(X_train.values)
            self.base_train_score = self.evaluator.calculate_rolling_sharpe_stability(
                pd.Series(train_pred, index=X_train.index), y_train,
                window_days=self.rolling_window_days, stability_penalty=self.stability_penalty
            )

            logger.info(f"After pruning: pool_size={len(self.alpha_pool)}, base_score={self.base_train_score:.4f}")

    def evaluate_combination(self, use_val: bool = False) -> Dict:
        """è¿”å›å½“å‰çš„ç»„åˆè¡¨ç°"""
        score = self.base_val_score if use_val else self.base_train_score
        return {'sharpe': score, 'composite_score': score}

    @property
    def weights(self):
        """å…¼å®¹æ€§å±æ€§ï¼šè¿”å›å½“å‰æƒé‡"""
        if self.current_weights is not None:
            return self.current_weights.tolist()
        return []