import numpy as np
import pandas as pd
import logging
from typing import Dict, List, Tuple, Optional
from sklearn.linear_model import Ridge
from config import TrainingConfig
# æ³¨æ„ï¼šè¿™é‡Œä¸å†å¯¼å…¥ ICDiversityEvaluator ä»¥é¿å…å¾ªç¯å¯¼å…¥
# æˆ‘ä»¬å°†åœ¨è¿è¡Œæ—¶é€šè¿‡ set_evaluator æ³¨å…¥å®ä¾‹

logger = logging.getLogger(__name__)

class ImprovedCombinationModel:
    """
    åŸºäº Ridge å›å½’çš„ç»„åˆæ¨¡å‹
    æ ¸å¿ƒï¼šReward = Incremental Rolling Sharpe Stability Score
    """

    def __init__(self, config: TrainingConfig, max_alpha_count: int = 15):
        self.config = config
        self.max_alpha_count = max_alpha_count
        
        # å› å­æ± ä¿¡æ¯
        self.alpha_pool: List[Dict] = []
        
        # å› å­æ•°æ®çŸ©é˜µ
        self.train_matrix: Optional[pd.DataFrame] = None
        self.val_matrix: Optional[pd.DataFrame] = None
        
        # ç›®æ ‡å€¼
        self.train_target: Optional[pd.Series] = None
        self.val_target: Optional[pd.Series] = None
        
        # æ¨¡å‹ä¸çŠ¶æ€
        self.ridge_model = Ridge(alpha=1.0, fit_intercept=False) 
        self.current_weights: Optional[np.ndarray] = None
        self.evaluator = None # ç±»å‹: ICDiversityEvaluator
        
        # ç¼“å­˜å½“å‰çš„åŸºå‡†åˆ†æ•°
        self.base_train_score = 0.0
        self.base_val_score = 0.0
        
        # Rolling Sharpe çš„å‚æ•°
        self.rolling_window_days = getattr(config, 'rolling_window_days', 90)
        self.stability_penalty = getattr(config, 'stability_penalty', 1.5)

    def set_evaluator(self, evaluator):
        self.evaluator = evaluator

    def set_targets(self, train_target: pd.Series, val_target: pd.Series):
        self.train_target = train_target
        self.val_target = val_target

    def _align_and_clean(self, X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:
        """å¯¹é½ç‰¹å¾å’Œç›®æ ‡ï¼Œå¹¶å¤„ç† NaN/Inf"""
        # 1. ç¡®ä¿ç´¢å¼•äº¤é›†
        valid_idx = X.index.intersection(y.index)
        
        # 2. ç­›é€‰å¹¶å¡«å……
        X_clean = X.loc[valid_idx].fillna(0.0).replace([np.inf, -np.inf], 0.0)
        y_clean = y.loc[valid_idx].fillna(0.0)
        
        return X_clean, y_clean

    def evaluate_new_factor(self, alpha_info: Dict, 
                           train_factor: pd.Series, val_factor: pd.Series) -> Dict:
        """
        ğŸ”¥ è¯•ç®—æ¨¡å¼ (Trial Mode): ä»…è®¡ç®—å¢é‡ç¨³å®šæ€§ï¼Œä¸ä¿®æ”¹æ± å­ã€‚
        """
        if self.evaluator is None or self.train_target is None: 
            return {'train_incremental_sharpe': 0.0, 'train_stats': {'sharpe': 0.0}, 'val_stats': {'sharpe': 0.0}}

        # 1. å¯¹é½æ–°å› å­æ•°æ®åˆ° Target ç´¢å¼• (å…³é”®ä¿®å¤ï¼šé˜²æ­¢ç´¢å¼•é”™ä½)
        train_factor_aligned = train_factor.reindex(self.train_target.index).fillna(0.0)
        
        # 2. æ„é€ ä¸´æ—¶è®­ç»ƒçŸ©é˜µ
        if self.train_matrix is None or len(self.alpha_pool) == 0:
            # Case A: æ± å­ä¸ºç©º
            temp_train_X = train_factor_aligned.to_frame(name='new')
        else:
            # Case B: æ‹¼æ¥ç°æœ‰çŸ©é˜µ (ä½¿ç”¨ reindex ç¡®ä¿ train_matrix ä¹Ÿå¯¹é½)
            # æ³¨æ„ï¼šè¿™é‡Œä¸ºäº†æ•ˆç‡ï¼Œåœ¨å®é™…å¤§è§„æ¨¡ç”Ÿäº§ä¸­åº”å°½é‡é¿å…æ¯æ¬¡éƒ½ concat DataFrame
            # ä½†ä¸ºäº†ä»£ç æ¸…æ™°åº¦ï¼Œä¿æŒ concat
            current_X = self.train_matrix.reindex(self.train_target.index).fillna(0.0)
            temp_train_X = pd.concat([current_X, train_factor_aligned.rename('new')], axis=1)

        # 3. æ‹Ÿåˆ Ridge å›å½’ (åœ¨ Train ä¸Š)
        X_train, y_train = self._align_and_clean(temp_train_X, self.train_target)
        
        if len(X_train) < 100: 
            return {'train_incremental_sharpe': 0.0, 'train_stats': {'sharpe': 0.0}, 'val_stats': {'sharpe': 0.0}}
        
        try:
            # æ‹Ÿåˆ
            self.ridge_model.fit(X_train.values, y_train.values)
            
            # é¢„æµ‹ç»„åˆæ”¶ç›Š
            train_pred_vals = self.ridge_model.predict(X_train.values)
            train_pred_series = pd.Series(train_pred_vals, index=X_train.index)
            
            # è®¡ç®—æ–°çš„ Stability Score
            new_train_score = self.evaluator.calculate_rolling_sharpe_stability(
                train_pred_series, y_train,
                window_days=self.rolling_window_days, stability_penalty=self.stability_penalty
            )
            
            # 4. è®¡ç®—å¢é‡ (Reward)
            incremental_score = new_train_score - self.base_train_score
            
            return {
                'train_incremental_sharpe': incremental_score, 
                'train_stats': {'sharpe': new_train_score, 'composite_score': new_train_score},
                # Val stats æš‚ç•¥ï¼Œä»¥èŠ‚çœè®¡ç®—èµ„æº
                'val_stats': {'sharpe': 0.0, 'composite_score': 0.0},
            }
        except Exception as e:
            logger.error(f"Combiner trial failed: {e}")
            return {'train_incremental_sharpe': 0.0, 'train_stats': {'sharpe': 0.0}, 'val_stats': {'sharpe': 0.0}}

    def add_alpha_and_optimize(self, alpha_info: Dict, 
                              train_factor: pd.Series, val_factor: pd.Series) -> Dict:
        """
        ğŸ”¥ æäº¤æ¨¡å¼ (Commit Mode): çœŸæ­£å°†å› å­åŠ å…¥æ± å­ï¼Œå¹¶æ›´æ–°åŸºå‡†çŠ¶æ€ã€‚
        """
        if self.train_target is None:
            return {}

        factor_name = f"alpha_{len(self.alpha_pool)}"
        
        # 1. æ›´æ–°å› å­æ± å…ƒæ•°æ®
        self.alpha_pool.append(alpha_info)
        
        # 2. æ›´æ–°æ•°æ®çŸ©é˜µ (å¼ºåˆ¶å¯¹é½)
        train_factor_aligned = train_factor.reindex(self.train_target.index).fillna(0.0)
        if self.val_target is not None:
            val_factor_aligned = val_factor.reindex(self.val_target.index).fillna(0.0)
        else:
            val_factor_aligned = pd.DataFrame()

        if self.train_matrix is None:
            self.train_matrix = train_factor_aligned.to_frame(name=factor_name)
            if not val_factor_aligned.empty:
                self.val_matrix = val_factor_aligned.to_frame(name=factor_name)
        else:
            self.train_matrix[factor_name] = train_factor_aligned
            if self.val_matrix is not None and not val_factor_aligned.empty:
                self.val_matrix[factor_name] = val_factor_aligned
            
        # 3. é‡æ–°æ‹ŸåˆåŸºå‡†æ¨¡å‹
        X_train, y_train = self._align_and_clean(self.train_matrix, self.train_target)
        
        if len(X_train) > 100:
            self.ridge_model.fit(X_train.values, y_train.values)
            self.current_weights = self.ridge_model.coef_
            
            # 4. ğŸ”¥ æ›´æ–°åŸºå‡† Rolling Stability Score
            train_pred_vals = self.ridge_model.predict(X_train.values)
            train_pred_series = pd.Series(train_pred_vals, index=X_train.index)
            
            self.base_train_score = self.evaluator.calculate_rolling_sharpe_stability(
                train_pred_series, y_train,
                window_days=self.rolling_window_days, stability_penalty=self.stability_penalty
            )
            
            # Val Score Update (å¦‚æœéœ€è¦)
            if self.val_matrix is not None and self.val_target is not None:
                X_val, y_val = self._align_and_clean(self.val_matrix, self.val_target)
                if len(X_val) > 50:
                    val_pred = self.ridge_model.predict(X_val.values)
                    self.base_val_score = self.evaluator.calculate_rolling_sharpe_stability(
                        pd.Series(val_pred, index=X_val.index), y_val,
                        window_days=self.rolling_window_days, stability_penalty=self.stability_penalty
                    )
        
        # 5. æ·˜æ±°æœ€å·®å› å­ (å¦‚æœæ± å­æ»¡äº†)
        if len(self.alpha_pool) > self.max_alpha_count:
            self._prune_factor()
            
        return {
            'pool_size': len(self.alpha_pool),
            'current_train_score': self.base_train_score,
            'current_val_score': self.base_val_score
        }

    def _prune_factor(self):
        """
        æ·˜æ±°æœºåˆ¶ï¼šç§»é™¤æƒé‡ç»å¯¹å€¼æœ€å°çš„å› å­
        """
        if self.current_weights is None or len(self.alpha_pool) <= self.max_alpha_count: 
            return
        
        # æ‰¾åˆ°æƒé‡ç»å¯¹å€¼æœ€å°çš„ç´¢å¼•
        min_idx = np.argmin(np.abs(self.current_weights))
        
        # è®°å½•å¹¶ç§»é™¤
        col_to_drop = self.train_matrix.columns[min_idx]
        
        # ç§»é™¤ Metadata
        self.alpha_pool.pop(min_idx)
        
        # æ›´æ–°çŸ©é˜µ
        self.train_matrix.drop(columns=[col_to_drop], inplace=True)
        if self.val_matrix is not None:
            self.val_matrix.drop(columns=[col_to_drop], inplace=True)
            
        # æ›´æ–°æƒé‡æ•°ç»„
        self.current_weights = np.delete(self.current_weights, min_idx)
        
        # è¿™é‡Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©é‡æ–° fitï¼Œä¹Ÿå¯ä»¥æš‚æ—¶ä¿æŒ current_weights ç›´åˆ°ä¸‹ä¸€æ¬¡ add
        # ä¸ºäº†ä¿æŒ base_score å‡†ç¡®ï¼Œå»ºè®®é‡æ–° fit
        X_train, y_train = self._align_and_clean(self.train_matrix, self.train_target)
        if len(X_train) > 100:
            self.ridge_model.fit(X_train.values, y_train.values)
            self.current_weights = self.ridge_model.coef_
            
            # æ›´æ–° Base Score
            train_pred = self.ridge_model.predict(X_train.values)
            self.base_train_score = self.evaluator.calculate_rolling_sharpe_stability(
                pd.Series(train_pred, index=X_train.index), y_train,
                window_days=self.rolling_window_days, stability_penalty=self.stability_penalty
            )

    def evaluate_combination(self, use_val: bool = False) -> Dict:
        """è¿”å›å½“å‰çš„ç»„åˆè¡¨ç°"""
        score = self.base_val_score if use_val else self.base_train_score
        return {'sharpe': score, 'composite_score': score}